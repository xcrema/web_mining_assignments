{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <center>WEB MINING ASSIGNMENT 1</center><BR><br>\n",
    "    NAME: ACHYUT TRIPATHI<BR><BR>\n",
    "    REGNO: 17BCE0954<br><br>\n",
    "    Slot: L45+L46\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ques1: Write a program to extract the source content (excluding any tags) from the website (https://en.wikipedia.org/wiki/Web_mining). Display the number of terms and term frequency of each term present in them after applying stop word removal. Also, apply stemming and lemmatization to the same document and display the number of terms along with their corresponding stemmed as well as lemmatized words present in them. Count the total number of stemmed and lemmatized words.\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get(\"https://en.wikipedia.org/wiki/Web_mining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(url.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (line.strip() for line in text.splitlines())\n",
    "# break multi-headlines into a line each\n",
    "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# drop blank lines\n",
    "text = '\\n'.join(chunk for chunk in chunks if chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_text = [w for w in word_tokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Terms after removing Stop Words:  2886\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Terms after removing Stop Words: \", len(filt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_count = {}\n",
    "for i in filt_text:\n",
    "    count = 0\n",
    "    if i not in term_count.keys():\n",
    "        for j in filt_text:\n",
    "            if i==j:\n",
    "                count+=1\n",
    "        term_count[i] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of  Web :  94\n",
      "Count of  mining :  69\n",
      "Count of  - :  3\n",
      "Count of  Wikipedia :  7\n",
      "Count of  From :  1\n",
      "Count of  , :  232\n",
      "Count of  free :  1\n",
      "Count of  encyclopedia :  1\n",
      "Count of  Jump :  2\n",
      "Count of  navigation :  2\n",
      "Count of  search :  3\n",
      "Count of  This :  12\n",
      "Count of  article :  4\n",
      "Count of  may :  2\n",
      "Count of  require :  2\n",
      "Count of  cleanup :  4\n",
      "Count of  meet :  1\n",
      "Count of  's :  5\n",
      "Count of  quality :  1\n",
      "Count of  standards :  2\n",
      "Count of  . :  146\n",
      "Count of  No :  2\n",
      "Count of  reason :  2\n",
      "Count of  specified :  1\n",
      "Count of  Please :  2\n",
      "Count of  help :  3\n",
      "Count of  improve :  3\n",
      "Count of  ( :  33\n",
      "Count of  June :  6\n",
      "Count of  2009 :  2\n",
      "Count of  ) :  33\n",
      "Count of  Learn :  2\n",
      "Count of  remove :  2\n",
      "Count of  template :  2\n",
      "Count of  message :  3\n",
      "Count of  application :  6\n",
      "Count of  data :  43\n",
      "Count of  techniques :  8\n",
      "Count of  discover :  4\n",
      "Count of  patterns :  9\n",
      "Count of  World :  6\n",
      "Count of  Wide :  7\n",
      "Count of  As :  3\n",
      "Count of  name :  2\n",
      "Count of  proposes :  1\n",
      "Count of  information :  17\n",
      "Count of  gathered :  1\n",
      "Count of  web :  29\n",
      "Count of  It :  4\n",
      "Count of  makes :  3\n",
      "Count of  utilization :  1\n",
      "Count of  automated :  2\n",
      "Count of  apparatuses :  1\n",
      "Count of  reveal :  2\n",
      "Count of  extricate :  1\n",
      "Count of  servers :  2\n",
      "Count of  web2 :  1\n",
      "Count of  reports :  1\n",
      "Count of  permits :  2\n",
      "Count of  organizations :  1\n",
      "Count of  get :  1\n",
      "Count of  organized :  1\n",
      "Count of  unstructured :  3\n",
      "Count of  browser :  1\n",
      "Count of  activities :  2\n",
      "Count of  server :  5\n",
      "Count of  logs :  5\n",
      "Count of  website :  2\n",
      "Count of  link :  2\n",
      "Count of  structure :  27\n",
      "Count of  page :  12\n",
      "Count of  content :  15\n",
      "Count of  different :  6\n",
      "Count of  sources :  3\n",
      "Count of  The :  21\n",
      "Count of  goal :  1\n",
      "Count of  generate :  2\n",
      "Count of  structural :  4\n",
      "Count of  summary :  1\n",
      "Count of  site :  9\n",
      "Count of  Technically :  1\n",
      "Count of  mainly :  1\n",
      "Count of  focuses :  1\n",
      "Count of  inner-document :  1\n",
      "Count of  tries :  2\n",
      "Count of  hyperlinks :  4\n",
      "Count of  inter-document :  1\n",
      "Count of  level :  3\n",
      "Count of  Based :  3\n",
      "Count of  topology :  1\n",
      "Count of  categorize :  3\n",
      "Count of  pages :  5\n",
      "Count of  similarity :  1\n",
      "Count of  relationship :  3\n",
      "Count of  sites :  2\n",
      "Count of  also :  5\n",
      "Count of  another :  1\n",
      "Count of  direction :  1\n",
      "Count of  – :  5\n",
      "Count of  discovering :  1\n",
      "Count of  document :  5\n",
      "Count of  type :  3\n",
      "Count of  used :  8\n",
      "Count of  schema :  3\n",
      "Count of  would :  1\n",
      "Count of  good :  1\n",
      "Count of  purpose :  2\n",
      "Count of  make :  3\n",
      "Count of  possible :  1\n",
      "Count of  compare/integrate :  1\n",
      "Count of  schemes :  1\n",
      "Count of  facilitate :  1\n",
      "Count of  introducing :  2\n",
      "Count of  database :  4\n",
      "Count of  accessing :  1\n",
      "Count of  providing :  2\n",
      "Count of  reference :  2\n",
      "Count of  Contents :  2\n",
      "Count of  1 :  5\n",
      "Count of  types :  4\n",
      "Count of  2 :  5\n",
      "Count of  usage :  20\n",
      "Count of  2.1 :  1\n",
      "Count of  Pros :  2\n",
      "Count of  2.2 :  1\n",
      "Count of  Cons :  2\n",
      "Count of  3 :  2\n",
      "Count of  4 :  3\n",
      "Count of  4.1 :  1\n",
      "Count of  foreign :  2\n",
      "Count of  languages :  2\n",
      "Count of  4.1.1 :  1\n",
      "Count of  Chinese :  4\n",
      "Count of  5 :  2\n",
      "Count of  See :  2\n",
      "Count of  6 :  5\n",
      "Count of  References :  2\n",
      "Count of  7 :  3\n",
      "Count of  Resources :  2\n",
      "Count of  7.1 :  1\n",
      "Count of  External :  2\n",
      "Count of  links :  7\n",
      "Count of  7.2 :  1\n",
      "Count of  Books :  2\n",
      "Count of  7.3 :  1\n",
      "Count of  Bibliographic :  2\n",
      "Count of  references :  3\n",
      "Count of  [ :  26\n",
      "Count of  edit :  14\n",
      "Count of  ] :  26\n",
      "Count of  divided :  2\n",
      "Count of  three :  1\n",
      "Count of  general :  2\n",
      "Count of  categories :  4\n",
      "Count of  objectives :  1\n",
      "Count of  Comparison :  1\n",
      "Count of  IR :  1\n",
      "Count of  view :  6\n",
      "Count of  DB :  2\n",
      "Count of  View :  3\n",
      "Count of  Unstructured :  1\n",
      "Count of  Structured :  2\n",
      "Count of  Semi-structured :  1\n",
      "Count of  Link :  3\n",
      "Count of  Interactivity :  1\n",
      "Count of  Main :  2\n",
      "Count of  Text :  2\n",
      "Count of  documents :  11\n",
      "Count of  Hypertext :  3\n",
      "Count of  Server :  3\n",
      "Count of  Browser :  1\n",
      "Count of  Representation :  1\n",
      "Count of  Bag :  1\n",
      "Count of  words :  5\n",
      "Count of  n-gram :  1\n",
      "Count of  terms :  2\n",
      "Count of  phrases :  1\n",
      "Count of  concepts :  1\n",
      "Count of  ontology :  1\n",
      "Count of  Relational :  4\n",
      "Count of  Edge :  1\n",
      "Count of  labed :  1\n",
      "Count of  graph :  5\n",
      "Count of  Graph :  2\n",
      "Count of  table :  1\n",
      "Count of  Method :  2\n",
      "Count of  Machine :  3\n",
      "Count of  learning :  2\n",
      "Count of  Statistical :  2\n",
      "Count of  including :  2\n",
      "Count of  NLP :  1\n",
      "Count of  Proprietary :  2\n",
      "Count of  algorithms :  5\n",
      "Count of  Association :  4\n",
      "Count of  rules :  3\n",
      "Count of  Application :  3\n",
      "Count of  Categorization :  2\n",
      "Count of  Clustering :  3\n",
      "Count of  Finding :  4\n",
      "Count of  extract :  2\n",
      "Count of  text :  4\n",
      "Count of  frequent :  1\n",
      "Count of  sub :  1\n",
      "Count of  structures :  3\n",
      "Count of  discovery :  2\n",
      "Count of  Site :  2\n",
      "Count of  construction :  1\n",
      "Count of  Adaptation :  1\n",
      "Count of  management :  3\n",
      "Count of  interesting :  1\n",
      "Count of  order :  2\n",
      "Count of  understand :  1\n",
      "Count of  better :  4\n",
      "Count of  serve :  1\n",
      "Count of  needs :  5\n",
      "Count of  Web-based :  1\n",
      "Count of  applications :  6\n",
      "Count of  Usage :  8\n",
      "Count of  captures :  1\n",
      "Count of  identity :  1\n",
      "Count of  origin :  1\n",
      "Count of  users :  3\n",
      "Count of  along :  1\n",
      "Count of  browsing :  2\n",
      "Count of  behavior :  2\n",
      "Count of  classified :  1\n",
      "Count of  depending :  1\n",
      "Count of  kind :  1\n",
      "Count of  considered :  3\n",
      "Count of  : :  36\n",
      "Count of  user :  10\n",
      "Count of  collected :  2\n",
      "Count of  Typical :  1\n",
      "Count of  includes :  2\n",
      "Count of  IP :  1\n",
      "Count of  address :  2\n",
      "Count of  access :  2\n",
      "Count of  time :  2\n",
      "Count of  Commercial :  1\n",
      "Count of  significant :  1\n",
      "Count of  features :  4\n",
      "Count of  enable :  1\n",
      "Count of  e-commerce :  2\n",
      "Count of  built :  1\n",
      "Count of  top :  1\n",
      "Count of  little :  1\n",
      "Count of  effort :  1\n",
      "Count of  A :  3\n",
      "Count of  key :  1\n",
      "Count of  feature :  4\n",
      "Count of  ability :  1\n",
      "Count of  track :  1\n",
      "Count of  various :  1\n",
      "Count of  kinds :  3\n",
      "Count of  business :  1\n",
      "Count of  events :  3\n",
      "Count of  log :  2\n",
      "Count of  New :  1\n",
      "Count of  defined :  3\n",
      "Count of  logging :  1\n",
      "Count of  turned :  1\n",
      "Count of  thus :  2\n",
      "Count of  generating :  1\n",
      "Count of  histories :  1\n",
      "Count of  specially :  1\n",
      "Count of  Many :  1\n",
      "Count of  end :  1\n",
      "Count of  combination :  1\n",
      "Count of  one :  4\n",
      "Count of  applied :  3\n",
      "Count of  Studies :  1\n",
      "Count of  related :  1\n",
      "Count of  work :  1\n",
      "Count of  concerned :  1\n",
      "Count of  two :  4\n",
      "Count of  areas :  1\n",
      "Count of  constraint-based :  1\n",
      "Count of  developed :  1\n",
      "Count of  software :  1\n",
      "Count of  tools :  4\n",
      "Count of  systems :  2\n",
      "Count of  Costa :  2\n",
      "Count of  Seco :  2\n",
      "Count of  demonstrated :  1\n",
      "Count of  semantic :  3\n",
      "Count of  hyponymy :  1\n",
      "Count of  relationships :  1\n",
      "Count of  particular :  4\n",
      "Count of  given :  2\n",
      "Count of  community :  1\n",
      "Count of  essentially :  2\n",
      "Count of  many :  1\n",
      "Count of  advantages :  1\n",
      "Count of  technology :  6\n",
      "Count of  attractive :  1\n",
      "Count of  corporations :  1\n",
      "Count of  government :  1\n",
      "Count of  agencies :  2\n",
      "Count of  enabled :  1\n",
      "Count of  personalized :  1\n",
      "Count of  marketing :  1\n",
      "Count of  eventually :  1\n",
      "Count of  results :  2\n",
      "Count of  higher :  2\n",
      "Count of  trade :  2\n",
      "Count of  volumes :  1\n",
      "Count of  Government :  1\n",
      "Count of  using :  3\n",
      "Count of  classify :  1\n",
      "Count of  threats :  1\n",
      "Count of  fight :  1\n",
      "Count of  terrorism :  1\n",
      "Count of  predicting :  1\n",
      "Count of  capability :  2\n",
      "Count of  benefit :  1\n",
      "Count of  society :  1\n",
      "Count of  identifying :  1\n",
      "Count of  criminal :  1\n",
      "Count of  Companies :  2\n",
      "Count of  establish :  1\n",
      "Count of  customer :  7\n",
      "Count of  understanding :  1\n",
      "Count of  reacting :  1\n",
      "Count of  faster :  1\n",
      "Count of  find :  3\n",
      "Count of  attract :  1\n",
      "Count of  retain :  2\n",
      "Count of  customers :  3\n",
      "Count of  ; :  17\n",
      "Count of  save :  1\n",
      "Count of  production :  1\n",
      "Count of  costs :  1\n",
      "Count of  utilizing :  1\n",
      "Count of  acquired :  1\n",
      "Count of  insight :  1\n",
      "Count of  requirements :  1\n",
      "Count of  They :  3\n",
      "Count of  increase :  1\n",
      "Count of  profitability :  1\n",
      "Count of  target :  2\n",
      "Count of  pricing :  1\n",
      "Count of  based :  4\n",
      "Count of  profiles :  3\n",
      "Count of  created :  1\n",
      "Count of  even :  1\n",
      "Count of  might :  6\n",
      "Count of  default :  1\n",
      "Count of  competitor :  1\n",
      "Count of  company :  2\n",
      "Count of  try :  1\n",
      "Count of  promotional :  1\n",
      "Count of  offers :  1\n",
      "Count of  specific :  4\n",
      "Count of  reducing :  1\n",
      "Count of  risk :  1\n",
      "Count of  losing :  1\n",
      "Count of  More :  2\n",
      "Count of  benefits :  2\n",
      "Count of  particularly :  1\n",
      "Count of  area :  1\n",
      "Count of  personalization :  3\n",
      "Count of  outlined :  1\n",
      "Count of  frameworks :  1\n",
      "Count of  probabilistic :  1\n",
      "Count of  latent :  1\n",
      "Count of  analysis :  3\n",
      "Count of  model :  2\n",
      "Count of  offer :  1\n",
      "Count of  additional :  3\n",
      "Count of  pattern :  2\n",
      "Count of  process :  2\n",
      "Count of  provides :  1\n",
      "Count of  relevant :  1\n",
      "Count of  collaborative :  1\n",
      "Count of  recommendation :  1\n",
      "Count of  These :  3\n",
      "Count of  models :  1\n",
      "Count of  demonstrate :  1\n",
      "Count of  problems :  1\n",
      "Count of  associated :  1\n",
      "Count of  traditional :  2\n",
      "Count of  biases :  1\n",
      "Count of  questions :  1\n",
      "Count of  regarding :  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of  validity :  2\n",
      "Count of  since :  1\n",
      "Count of  obtained :  6\n",
      "Count of  subjective :  1\n",
      "Count of  degrade :  1\n",
      "Count of  There :  2\n",
      "Count of  elements :  1\n",
      "Count of  unique :  1\n",
      "Count of  show :  1\n",
      "Count of  include :  1\n",
      "Count of  way :  1\n",
      "Count of  knowledge :  4\n",
      "Count of  interpreting :  1\n",
      "Count of  analyzing :  1\n",
      "Count of  reasoning :  1\n",
      "Count of  phase :  1\n",
      "Count of  create :  1\n",
      "Count of  issues :  2\n",
      "Count of  personal :  4\n",
      "Count of  nature :  1\n",
      "Count of  cause :  1\n",
      "Count of  concerns :  1\n",
      "Count of  criticized :  1\n",
      "Count of  ethical :  2\n",
      "Count of  issue :  1\n",
      "Count of  involving :  1\n",
      "Count of  invasion :  1\n",
      "Count of  privacy :  3\n",
      "Count of  Privacy :  5\n",
      "Count of  lost :  1\n",
      "Count of  concerning :  1\n",
      "Count of  individual :  4\n",
      "Count of  disseminated :  1\n",
      "Count of  especially :  1\n",
      "Count of  occurs :  1\n",
      "Count of  without :  3\n",
      "Count of  consent :  1\n",
      "Count of  analyzed :  1\n",
      "Count of  clustered :  1\n",
      "Count of  form :  1\n",
      "Count of  made :  2\n",
      "Count of  anonymous :  3\n",
      "Count of  clustering :  1\n",
      "Count of  Thus :  1\n",
      "Count of  de-individualize :  1\n",
      "Count of  judging :  2\n",
      "Count of  mouse :  1\n",
      "Count of  clicks :  1\n",
      "Count of  De-individualization :  1\n",
      "Count of  tendency :  1\n",
      "Count of  treating :  1\n",
      "Count of  people :  1\n",
      "Count of  basis :  1\n",
      "Count of  group :  1\n",
      "Count of  characteristics :  2\n",
      "Count of  instead :  1\n",
      "Count of  merits :  2\n",
      "Count of  Another :  1\n",
      "Count of  important :  2\n",
      "Count of  concern :  1\n",
      "Count of  companies :  3\n",
      "Count of  collecting :  1\n",
      "Count of  use :  5\n",
      "Count of  totally :  1\n",
      "Count of  purposes :  1\n",
      "Count of  violates :  1\n",
      "Count of  interests :  1\n",
      "Count of  growing :  1\n",
      "Count of  trend :  2\n",
      "Count of  selling :  1\n",
      "Count of  commodity :  1\n",
      "Count of  encourages :  1\n",
      "Count of  owners :  1\n",
      "Count of  increased :  1\n",
      "Count of  amount :  1\n",
      "Count of  captured :  1\n",
      "Count of  traded :  1\n",
      "Count of  increasing :  1\n",
      "Count of  likeliness :  1\n",
      "Count of  invaded :  1\n",
      "Count of  buy :  1\n",
      "Count of  obliged :  1\n",
      "Count of  authors :  1\n",
      "Count of  release :  3\n",
      "Count of  legally :  1\n",
      "Count of  responsible :  1\n",
      "Count of  contents :  1\n",
      "Count of  inaccuracies :  1\n",
      "Count of  result :  3\n",
      "Count of  serious :  1\n",
      "Count of  lawsuits :  1\n",
      "Count of  law :  1\n",
      "Count of  preventing :  1\n",
      "Count of  trading :  1\n",
      "Count of  Some :  1\n",
      "Count of  controversial :  2\n",
      "Count of  attributes :  3\n",
      "Count of  like :  1\n",
      "Count of  sex :  1\n",
      "Count of  race :  2\n",
      "Count of  religion :  2\n",
      "Count of  sexual :  2\n",
      "Count of  orientation :  2\n",
      "Count of  individuals :  1\n",
      "Count of  practices :  1\n",
      "Count of  anti-discrimination :  1\n",
      "Count of  legislation :  1\n",
      "Count of  hard :  1\n",
      "Count of  identify :  3\n",
      "Count of  strong :  1\n",
      "Count of  rule :  1\n",
      "Count of  could :  1\n",
      "Count of  denial :  1\n",
      "Count of  service :  1\n",
      "Count of  privilege :  1\n",
      "Count of  situation :  1\n",
      "Count of  avoided :  1\n",
      "Count of  high :  1\n",
      "Count of  maintained :  1\n",
      "Count of  traced :  1\n",
      "Count of  back :  1\n",
      "Count of  look :  1\n",
      "Count of  poses :  1\n",
      "Count of  threat :  1\n",
      "Count of  however :  1\n",
      "Count of  inferred :  1\n",
      "Count of  combining :  1\n",
      "Count of  separate :  1\n",
      "Count of  unscrupulous :  1\n",
      "Count of  section :  2\n",
      "Count of  expansion :  1\n",
      "Count of  You :  1\n",
      "Count of  adding :  1\n",
      "Count of  2015 :  1\n",
      "Count of  uses :  1\n",
      "Count of  theory :  1\n",
      "Count of  analyze :  1\n",
      "Count of  node :  5\n",
      "Count of  connection :  1\n",
      "Count of  According :  1\n",
      "Count of  Extracting :  1\n",
      "Count of  hyperlink :  2\n",
      "Count of  component :  2\n",
      "Count of  connects :  1\n",
      "Count of  location :  1\n",
      "Count of  Mining :  20\n",
      "Count of  tree-like :  1\n",
      "Count of  describe :  1\n",
      "Count of  HTML :  3\n",
      "Count of  XML :  1\n",
      "Count of  tag :  1\n",
      "Count of  terminology :  1\n",
      "Count of  directed :  1\n",
      "Count of  representing :  1\n",
      "Count of  edge :  1\n",
      "Count of  degree :  2\n",
      "Count of  number :  3\n",
      "Count of  pointing :  2\n",
      "Count of  generated :  1\n",
      "Count of  Techniques :  2\n",
      "Count of  PageRank :  1\n",
      "Count of  algorithm :  3\n",
      "Count of  Google :  1\n",
      "Count of  rank :  2\n",
      "Count of  Google-founder :  1\n",
      "Count of  Larry :  1\n",
      "Count of  Page :  1\n",
      "Count of  decided :  1\n",
      "Count of  extraction :  2\n",
      "Count of  integration :  1\n",
      "Count of  useful :  3\n",
      "Count of  heterogeneity :  1\n",
      "Count of  lack :  1\n",
      "Count of  much :  1\n",
      "Count of  ever-expanding :  1\n",
      "Count of  hypertext :  1\n",
      "Count of  organization :  3\n",
      "Count of  indexing :  1\n",
      "Count of  Internet :  2\n",
      "Count of  Lycos :  1\n",
      "Count of  Alta :  1\n",
      "Count of  Vista :  1\n",
      "Count of  WebCrawler :  1\n",
      "Count of  Aliweb :  1\n",
      "Count of  MetaCrawler :  1\n",
      "Count of  others :  1\n",
      "Count of  provide :  3\n",
      "Count of  comfort :  1\n",
      "Count of  generally :  1\n",
      "Count of  filter :  1\n",
      "Count of  interpret :  1\n",
      "Count of  factors :  1\n",
      "Count of  prompted :  1\n",
      "Count of  researchers :  1\n",
      "Count of  develop :  1\n",
      "Count of  intelligent :  2\n",
      "Count of  retrieval :  2\n",
      "Count of  agents :  1\n",
      "Count of  well :  1\n",
      "Count of  extend :  1\n",
      "Count of  semi-structured :  3\n",
      "Count of  available :  2\n",
      "Count of  agent-based :  1\n",
      "Count of  approach :  1\n",
      "Count of  involves :  1\n",
      "Count of  development :  1\n",
      "Count of  sophisticated :  1\n",
      "Count of  AI :  1\n",
      "Count of  act :  1\n",
      "Count of  autonomously :  1\n",
      "Count of  semi-autonomously :  1\n",
      "Count of  behalf :  1\n",
      "Count of  organize :  1\n",
      "Count of  web-based :  1\n",
      "Count of  differentiated :  1\n",
      "Count of  points :  1\n",
      "Count of  8 :  1\n",
      "Count of  Information :  6\n",
      "Count of  Retrieval :  1\n",
      "Count of  Database :  1\n",
      "Count of  9 :  1\n",
      "Count of  summarized :  1\n",
      "Count of  research :  1\n",
      "Count of  works :  2\n",
      "Count of  done :  1\n",
      "Count of  shows :  1\n",
      "Count of  researches :  1\n",
      "Count of  bag :  1\n",
      "Count of  statistics :  1\n",
      "Count of  single :  2\n",
      "Count of  isolation :  1\n",
      "Count of  represent :  2\n",
      "Count of  take :  1\n",
      "Count of  word :  2\n",
      "Count of  found :  1\n",
      "Count of  training :  1\n",
      "Count of  corpus :  1\n",
      "Count of  For :  1\n",
      "Count of  utilize :  1\n",
      "Count of  inside :  1\n",
      "Count of  utilized :  1\n",
      "Count of  representation :  2\n",
      "Count of  querying :  1\n",
      "Count of  always :  1\n",
      "Count of  infer :  1\n",
      "Count of  transform :  2\n",
      "Count of  become :  1\n",
      "Count of  several :  1\n",
      "Count of  ways :  1\n",
      "Count of  vector :  2\n",
      "Count of  space :  2\n",
      "Count of  typically :  1\n",
      "Count of  constitute :  1\n",
      "Count of  whole :  1\n",
      "Count of  realize :  1\n",
      "Count of  importance :  1\n",
      "Count of  To :  1\n",
      "Count of  resolve :  1\n",
      "Count of  tf-idf :  1\n",
      "Count of  Term :  1\n",
      "Count of  Frequency :  2\n",
      "Count of  Times :  1\n",
      "Count of  Inverse :  1\n",
      "Count of  Document :  1\n",
      "Count of  introduced :  1\n",
      "Count of  By :  2\n",
      "Count of  multi-scanning :  1\n",
      "Count of  implement :  1\n",
      "Count of  selection :  1\n",
      "Count of  Under :  1\n",
      "Count of  condition :  1\n",
      "Count of  category :  1\n",
      "Count of  rarely :  1\n",
      "Count of  affected :  1\n",
      "Count of  subset :  1\n",
      "Count of  needed :  1\n",
      "Count of  construct :  1\n",
      "Count of  evaluating :  1\n",
      "Count of  function :  1\n",
      "Count of  evaluate :  1\n",
      "Count of  set :  1\n",
      "Count of  gain :  1\n",
      "Count of  cross :  1\n",
      "Count of  entropy :  1\n",
      "Count of  mutual :  1\n",
      "Count of  odds :  1\n",
      "Count of  ratio :  1\n",
      "Count of  usually :  1\n",
      "Count of  classifier :  1\n",
      "Count of  methods :  1\n",
      "Count of  similar :  1\n",
      "Count of  usual :  1\n",
      "Count of  evaluative :  1\n",
      "Count of  classification :  1\n",
      "Count of  accuracy :  1\n",
      "Count of  precision :  1\n",
      "Count of  recall :  1\n",
      "Count of  score :  1\n",
      "Count of  pipeline :  1\n",
      "Count of  portals :  1\n",
      "Count of  confirmation :  1\n",
      "Count of  verification :  1\n",
      "Count of  integrity :  1\n",
      "Count of  building :  1\n",
      "Count of  taxonomies :  1\n",
      "Count of  generation :  1\n",
      "Count of  opinion :  1\n",
      "Count of  10 :  1\n",
      "Count of  language :  1\n",
      "Count of  code :  4\n",
      "Count of  complicated :  1\n",
      "Count of  compared :  1\n",
      "Count of  English :  1\n",
      "Count of  GB :  1\n",
      "Count of  Big5 :  1\n",
      "Count of  HZ :  1\n",
      "Count of  common :  1\n",
      "Count of  codes :  1\n",
      "Count of  Before :  1\n",
      "Count of  standard :  1\n",
      "Count of  inner :  1\n",
      "Count of  intelligence :  1\n",
      "Count of  analytics :  1\n",
      "Count of  scraping :  2\n",
      "Count of  Data :  16\n",
      "Count of  ^ :  10\n",
      "Count of  Galitsky :  2\n",
      "Count of  B. :  5\n",
      "Count of  Dobrocsi :  2\n",
      "Count of  G. :  2\n",
      "Count of  de :  3\n",
      "Count of  la :  2\n",
      "Count of  Rosa :  2\n",
      "Count of  J. :  2\n",
      "Count of  L. :  2\n",
      "Count of  Kuznetsov :  2\n",
      "Count of  S. :  1\n",
      "Count of  O.. :  1\n",
      "Count of  Using :  3\n",
      "Count of  generalization :  2\n",
      "Count of  syntactic :  2\n",
      "Count of  parse :  2\n",
      "Count of  trees :  2\n",
      "Count of  taxonomy :  2\n",
      "Count of  capture :  2\n",
      "Count of  ICCS :  2\n",
      "Count of  2011 :  2\n",
      "Count of  8323 :  2\n",
      "Count of  Weichbroth :  2\n",
      "Count of  et :  1\n",
      "Count of  al :  1\n",
      "Count of  Ngu :  1\n",
      "Count of  Anne :  1\n",
      "Count of  Kitsuregawa :  1\n",
      "Count of  Masaru :  1\n",
      "Count of  Chung :  1\n",
      "Count of  Jen-Yao :  1\n",
      "Count of  Neuhold :  1\n",
      "Count of  Erich :  1\n",
      "Count of  Sheng :  1\n",
      "Count of  Quan :  1\n",
      "Count of  2005 :  6\n",
      "Count of  Systems :  2\n",
      "Count of  Engineering :  1\n",
      "Count of  WISE :  1\n",
      "Count of  Berlin :  2\n",
      "Count of  Springer :  5\n",
      "Count of  p. :  3\n",
      "Count of  15 :  1\n",
      "Count of  ISBN :  3\n",
      "Count of  9783540300175 :  1\n",
      "Count of  Bauknecht :  1\n",
      "Count of  Kurt :  1\n",
      "Count of  Madria :  1\n",
      "Count of  Sanjay :  1\n",
      "Count of  Pernul :  1\n",
      "Count of  Gunther :  1\n",
      "Count of  2000 :  5\n",
      "Count of  Electronic :  1\n",
      "Count of  Commerce :  1\n",
      "Count of  Technologies :  1\n",
      "Count of  First :  1\n",
      "Count of  International :  3\n",
      "Count of  Conference :  3\n",
      "Count of  EC-Web :  1\n",
      "Count of  London :  1\n",
      "Count of  UK :  1\n",
      "Count of  September :  3\n",
      "Count of  4-6 :  1\n",
      "Count of  Proceedings :  4\n",
      "Count of  165 :  1\n",
      "Count of  978-3540679813 :  1\n",
      "Count of  Scime :  1\n",
      "Count of  Anthony :  1\n",
      "Count of  Applications :  2\n",
      "Count of  Hershey :  1\n",
      "Count of  PA :  1\n",
      "Count of  Idea :  2\n",
      "Count of  Group :  2\n",
      "Count of  Publishing :  1\n",
      "Count of  pp :  6\n",
      "Count of  282 :  1\n",
      "Count of  978-1591404149 :  1\n",
      "Count of  b :  1\n",
      "Count of  c :  1\n",
      "Count of  Lita :  1\n",
      "Count of  van :  1\n",
      "Count of  Wel :  1\n",
      "Count of  & :  2\n",
      "Count of  Lambèr :  1\n",
      "Count of  Royakkers :  1\n",
      "Count of  2004 :  4\n",
      "Count of  `` :  15\n",
      "Count of  Ethical :  2\n",
      "Count of  '' :  19\n",
      "Count of  PDF :  2\n",
      "Count of  Issues :  3\n",
      "Count of  Mining.. :  2\n",
      "Count of  Kirsten :  1\n",
      "Count of  Maelstrom :  1\n",
      "Count of  John :  1\n",
      "Count of  F. :  2\n",
      "Count of  Rodrick :  1\n",
      "Count of  Vladimir :  1\n",
      "Count of  Estivill-Castro :  1\n",
      "Count of  Denise :  1\n",
      "Count of  Vries :  1\n",
      "Count of  2007 :  4\n",
      "Count of  Legal :  2\n",
      "Count of  Technical :  2\n",
      "Count of  Preservation :  2\n",
      "Count of  Wang :  2\n",
      "Count of  Yan :  1\n",
      "Count of  Knowledge :  4\n",
      "Count of  Discovery :  5\n",
      "Count of  Patterns :  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of  Kosala :  1\n",
      "Count of  Raymond :  1\n",
      "Count of  Hendrik :  1\n",
      "Count of  Blockeel :  1\n",
      "Count of  July :  1\n",
      "Count of  Research :  2\n",
      "Count of  Survey :  1\n",
      "Count of  SIGKDD :  1\n",
      "Count of  Explorations :  1\n",
      "Count of  arXiv :  1\n",
      "Count of  cs.LG/0011033 :  1\n",
      "Count of  B :  1\n",
      "Count of  G :  1\n",
      "Count of  JL :  1\n",
      "Count of  SO :  1\n",
      "Count of  list :  1\n",
      "Count of  remain :  1\n",
      "Count of  unclear :  1\n",
      "Count of  insufficient :  1\n",
      "Count of  inline :  1\n",
      "Count of  citations :  4\n",
      "Count of  precise :  1\n",
      "Count of  Future :  1\n",
      "Count of  Sites :  1\n",
      "Count of  = :  1\n",
      "Count of  Services :  1\n",
      "Count of  Zdravko :  1\n",
      "Count of  Markov :  1\n",
      "Count of  Daniel :  4\n",
      "Count of  T. :  2\n",
      "Count of  Larose :  1\n",
      "Count of  Uncovering :  1\n",
      "Count of  Content :  1\n",
      "Count of  Structure :  1\n",
      "Count of  Wiley :  1\n",
      "Count of  Jesus :  1\n",
      "Count of  Mena :  1\n",
      "Count of  Your :  1\n",
      "Count of  Website :  2\n",
      "Count of  Digital :  1\n",
      "Count of  Press :  2\n",
      "Count of  1999 :  3\n",
      "Count of  Soumen :  1\n",
      "Count of  Chakrabarti :  1\n",
      "Count of  Analysis :  5\n",
      "Count of  Semi :  1\n",
      "Count of  Morgan :  1\n",
      "Count of  Kaufmann :  1\n",
      "Count of  2002 :  1\n",
      "Count of  Bing :  2\n",
      "Count of  Liu :  2\n",
      "Count of  Exploring :  1\n",
      "Count of  Hyperlinks :  1\n",
      "Count of  Advances :  1\n",
      "Count of  revised :  2\n",
      "Count of  papers :  2\n",
      "Count of  th :  2\n",
      "Count of  workshop :  2\n",
      "Count of  Olfa :  2\n",
      "Count of  Nasraoui :  5\n",
      "Count of  Osmar :  1\n",
      "Count of  Zaiane :  1\n",
      "Count of  Myra :  1\n",
      "Count of  Spiliopoulou :  1\n",
      "Count of  Bamshad :  2\n",
      "Count of  Mobasher :  6\n",
      "Count of  Philip :  1\n",
      "Count of  Yu :  1\n",
      "Count of  Brij :  2\n",
      "Count of  Masand :  2\n",
      "Count of  Eds. :  2\n",
      "Count of  Lecture :  2\n",
      "Count of  Notes :  2\n",
      "Count of  Artificial :  4\n",
      "Count of  Intelligence :  4\n",
      "Count of  LNAI :  1\n",
      "Count of  4198 :  1\n",
      "Count of  2006 :  5\n",
      "Count of  Mike :  1\n",
      "Count of  Thelwall :  1\n",
      "Count of  An :  1\n",
      "Count of  Science :  1\n",
      "Count of  Approach :  1\n",
      "Count of  Academic :  1\n",
      "Count of  Baraglia :  1\n",
      "Count of  R. :  6\n",
      "Count of  Silvestri :  1\n",
      "Count of  Dynamic :  1\n",
      "Count of  intervention :  1\n",
      "Count of  In :  3\n",
      "Count of  Communications :  2\n",
      "Count of  ACM :  3\n",
      "Count of  50 :  1\n",
      "Count of  63-67 :  1\n",
      "Count of  Cooley :  3\n",
      "Count of  Srivastave :  1\n",
      "Count of  J :  3\n",
      "Count of  1997 :  1\n",
      "Count of  “ :  10\n",
      "Count of  Pattern :  2\n",
      "Count of  ” :  10\n",
      "Count of  9th :  1\n",
      "Count of  IEEE :  1\n",
      "Count of  Tool :  1\n",
      "Count of  Srivastava :  2\n",
      "Count of  Preparation :  1\n",
      "Count of  Browsing :  2\n",
      "Count of  Journal :  2\n",
      "Count of  System :  1\n",
      "Count of  Vol.1 :  1\n",
      "Count of  Issue :  2\n",
      "Count of  5–32 :  1\n",
      "Count of  RP :  1\n",
      "Count of  N. :  1\n",
      "Count of  Hyponymy :  1\n",
      "Count of  Extraction :  1\n",
      "Count of  Search :  2\n",
      "Count of  Behavior :  1\n",
      "Count of  On :  1\n",
      "Count of  Query :  1\n",
      "Count of  Reformulation :  1\n",
      "Count of  11th :  1\n",
      "Count of  Ibero-American :  1\n",
      "Count of  2008 :  1\n",
      "Count of  October :  1\n",
      "Count of  Kohavi :  1\n",
      "Count of  Mason :  1\n",
      "Count of  Zheng :  1\n",
      "Count of  Z :  1\n",
      "Count of  Lessons :  1\n",
      "Count of  Challenges :  1\n",
      "Count of  Retail :  1\n",
      "Count of  E-commerce :  1\n",
      "Count of  Learning :  1\n",
      "Count of  Vol :  3\n",
      "Count of  57 :  1\n",
      "Count of  83–113 :  1\n",
      "Count of  Lillian :  1\n",
      "Count of  Clark :  1\n",
      "Count of  I-Hsien :  3\n",
      "Count of  Ting :  3\n",
      "Count of  Chris :  3\n",
      "Count of  Kimble :  3\n",
      "Count of  Peter :  1\n",
      "Count of  Wright :  1\n",
      "Count of  Kudenko :  3\n",
      "Count of  Combining :  2\n",
      "Count of  ethnographic :  1\n",
      "Count of  clickstream :  1\n",
      "Count of  strategies :  1\n",
      "Count of  11 :  1\n",
      "Count of  January :  2\n",
      "Count of  Eirinaki :  1\n",
      "Count of  M. :  5\n",
      "Count of  Vazirgiannis :  1\n",
      "Count of  2003 :  5\n",
      "Count of  Personalization :  5\n",
      "Count of  Transactions :  1\n",
      "Count of  Technology :  1\n",
      "Count of  Vol.3 :  1\n",
      "Count of  No.1 :  1\n",
      "Count of  February :  1\n",
      "Count of  Automatic :  1\n",
      "Count of  43 :  1\n",
      "Count of  No.8 :  1\n",
      "Count of  142–151 :  1\n",
      "Count of  Dai :  1\n",
      "Count of  H. :  2\n",
      "Count of  Luo :  1\n",
      "Count of  Nakagawa :  1\n",
      "Count of  2001 :  2\n",
      "Count of  Effective :  2\n",
      "Count of  Rule :  1\n",
      "Count of  Discover :  1\n",
      "Count of  WIDM :  1\n",
      "Count of  Atlanta :  1\n",
      "Count of  GA :  1\n",
      "Count of  USA :  1\n",
      "Count of  9–15 :  1\n",
      "Count of  O. :  3\n",
      "Count of  Petenes :  1\n",
      "Count of  C. :  3\n",
      "Count of  Fuzzy :  3\n",
      "Count of  Inference :  1\n",
      "Count of  Proc :  1\n",
      "Count of  WebKDD :  1\n",
      "Count of  KDD :  1\n",
      "Count of  Workshop :  1\n",
      "Count of  Premise :  1\n",
      "Count of  Intelligent :  1\n",
      "Count of  Washington :  1\n",
      "Count of  DC :  1\n",
      "Count of  August :  2\n",
      "Count of  37 :  1\n",
      "Count of  Frigui :  1\n",
      "Count of  Joshi :  1\n",
      "Count of  A. :  1\n",
      "Count of  Krishnapuram :  1\n",
      "Count of  Access :  1\n",
      "Count of  Logs :  1\n",
      "Count of  Competitive :  1\n",
      "Count of  Eighth :  1\n",
      "Count of  Congress :  1\n",
      "Count of  Hsinchu :  1\n",
      "Count of  Taiwan :  1\n",
      "Count of  Invited :  1\n",
      "Count of  chapter :  1\n",
      "Count of  Encyclopedia :  1\n",
      "Count of  Warehousing :  1\n",
      "Count of  Ed :  1\n",
      "Count of  Pierrakos :  1\n",
      "Count of  D. :  2\n",
      "Count of  Paliouras :  1\n",
      "Count of  Papatheodorou :  1\n",
      "Count of  Spyropoulos :  1\n",
      "Count of  tool :  1\n",
      "Count of  survey :  1\n",
      "Count of  User :  2\n",
      "Count of  modelling :  1\n",
      "Count of  adapted :  1\n",
      "Count of  interaction :  1\n",
      "Count of  journal :  1\n",
      "Count of  Vol.13 :  1\n",
      "Count of  311–372 :  1\n",
      "Count of  Restore :  1\n",
      "Count of  Restoring :  1\n",
      "Count of  Missing :  1\n",
      "Count of  Side :  1\n",
      "Count of  Clickstream :  2\n",
      "Count of  UBB :  1\n",
      "Count of  Unexpected :  1\n",
      "Count of  Behaviour :  1\n",
      "Count of  ’ :  1\n",
      "Count of  Design :  1\n",
      "Count of  P. :  1\n",
      "Count of  Owoc :  1\n",
      "Count of  Pleszkun :  1\n",
      "Count of  2012 :  1\n",
      "Count of  Navigation :  3\n",
      "Count of  WWW :  1\n",
      "Count of  Log :  1\n",
      "Count of  Files :  1\n",
      "Count of  Retrieved :  1\n",
      "Count of  https :  1\n",
      "Count of  //en.wikipedia.org/w/index.php :  1\n",
      "Count of  ? :  1\n",
      "Count of  title=Web_mining :  1\n",
      "Count of  oldid=933573148 :  1\n",
      "Count of  Categories :  1\n",
      "Count of  analyticsData :  1\n",
      "Count of  miningWorld :  1\n",
      "Count of  WebHidden :  1\n",
      "Count of  Articles :  1\n",
      "Count of  needing :  3\n",
      "Count of  2009All :  2\n",
      "Count of  cleanupCleanup :  1\n",
      "Count of  tagged :  1\n",
      "Count of  articles :  3\n",
      "Count of  field :  1\n",
      "Count of  2009Wikipedia :  1\n",
      "Count of  2009Articles :  1\n",
      "Count of  expanded :  1\n",
      "Count of  2015All :  1\n",
      "Count of  expandedArticles :  1\n",
      "Count of  small :  1\n",
      "Count of  boxesArticles :  1\n",
      "Count of  lacking :  2\n",
      "Count of  in-text :  2\n",
      "Count of  menu :  1\n",
      "Count of  Personal :  1\n",
      "Count of  Not :  1\n",
      "Count of  logged :  1\n",
      "Count of  inTalkContributionsCreate :  1\n",
      "Count of  accountLog :  1\n",
      "Count of  Namespaces :  1\n",
      "Count of  ArticleTalk :  1\n",
      "Count of  Variants :  1\n",
      "Count of  Views :  1\n",
      "Count of  ReadEditView :  1\n",
      "Count of  history :  1\n",
      "Count of  pageContentsFeatured :  1\n",
      "Count of  contentCurrent :  1\n",
      "Count of  eventsRandom :  1\n",
      "Count of  articleDonate :  1\n",
      "Count of  WikipediaWikipedia :  1\n",
      "Count of  store :  1\n",
      "Count of  Interaction :  1\n",
      "Count of  HelpAbout :  1\n",
      "Count of  WikipediaCommunity :  1\n",
      "Count of  portalRecent :  1\n",
      "Count of  changesContact :  1\n",
      "Count of  Tools :  1\n",
      "Count of  What :  1\n",
      "Count of  hereRelated :  1\n",
      "Count of  changesUpload :  1\n",
      "Count of  fileSpecial :  1\n",
      "Count of  pagesPermanent :  1\n",
      "Count of  linkPage :  1\n",
      "Count of  informationWikidata :  1\n",
      "Count of  itemCite :  1\n",
      "Count of  Print/export :  1\n",
      "Count of  Create :  1\n",
      "Count of  bookDownload :  1\n",
      "Count of  PDFPrintable :  1\n",
      "Count of  version :  1\n",
      "Count of  Languages :  1\n",
      "Count of  العربيةDeutschEspañolEuskaraفارسیFrançais한국어हिन्दीHrvatskiMagyar日本語PortuguêsРусскийSlovenčinaไทย :  1\n",
      "Count of  Edit :  1\n",
      "Count of  last :  1\n",
      "Count of  edited :  1\n",
      "Count of  2020 :  1\n",
      "Count of  20:51 :  1\n",
      "Count of  UTC :  1\n",
      "Count of  Creative :  1\n",
      "Count of  Commons :  1\n",
      "Count of  Attribution-ShareAlike :  1\n",
      "Count of  License :  1\n",
      "Count of  apply :  1\n",
      "Count of  agree :  1\n",
      "Count of  Terms :  1\n",
      "Count of  Use :  1\n",
      "Count of  Policy :  1\n",
      "Count of  Wikipedia® :  1\n",
      "Count of  registered :  1\n",
      "Count of  trademark :  1\n",
      "Count of  Wikimedia :  1\n",
      "Count of  Foundation :  1\n",
      "Count of  Inc. :  1\n",
      "Count of  non-profit :  1\n",
      "Count of  policy :  1\n",
      "Count of  About :  1\n",
      "Count of  Disclaimers :  1\n",
      "Count of  Contact :  1\n",
      "Count of  Developers :  1\n",
      "Count of  Statistics :  1\n",
      "Count of  Cookie :  1\n",
      "Count of  statement :  1\n",
      "Count of  Mobile :  1\n"
     ]
    }
   ],
   "source": [
    "for i in term_count.keys():\n",
    "    print(\"Count of \", i, \": \", term_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Terms after removing Stop Words:  1158\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Unique Terms after removing Stop Words: \", len(term_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_groups = []\n",
    "lem_groups = []\n",
    "groups = []\n",
    "for w in list(term_count.keys()):\n",
    "    stem_groups.append(ps.stem(w))\n",
    "    lem_groups.append(lemmatizer.lemmatize(w))\n",
    "    groups.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Stemmed Words:  913\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Stemmed Words: \", len(list(dict.fromkeys(stem_groups))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lemmatized Words:  1110\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Lemmatized Words: \", len(list(dict.fromkeys(lem_groups))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Word\": groups, \"Stemmed Word\": stem_groups, \"Lemmatized Word\": lem_groups}\n",
    "df = pd.DataFrame(data, columns = ['Word', 'Stemmed Word', 'Lemmatized Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stemmed Word</th>\n",
       "      <th>Lemmatized Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web</td>\n",
       "      <td>web</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mining</td>\n",
       "      <td>mine</td>\n",
       "      <td>mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From</td>\n",
       "      <td>from</td>\n",
       "      <td>From</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word Stemmed Word Lemmatized Word\n",
       "0        Web          web             Web\n",
       "1     mining         mine          mining\n",
       "2          -            -               -\n",
       "3  Wikipedia    wikipedia       Wikipedia\n",
       "4       From         from            From"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>\n",
    "Ques2: Add one new word to NLTK stopword list and filter the content extracted from the website given in Q. No. 1 in order to display the number of terms present in them after excluding newly added stopwords and their term frequency count. Display the POS tag for all the stopwords, which are removed from the content.\n",
    "</H2>    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = (stopwords.words('english'))\n",
    "stop_words.append('patterns')\n",
    "stop_words = set(stop_words)\n",
    "word_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_text = [w for w in word_tokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Terms after removing Stop Words:  2877\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Terms after removing Stop Words: \", len(filt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_count = {}\n",
    "for i in filt_text:\n",
    "    count = 0\n",
    "    if i not in term_count.keys():\n",
    "        for j in filt_text:\n",
    "            if i==j:\n",
    "                count+=1\n",
    "        term_count[i] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of  Web :  94\n",
      "Count of  mining :  69\n",
      "Count of  - :  3\n",
      "Count of  Wikipedia :  7\n",
      "Count of  From :  1\n",
      "Count of  , :  232\n",
      "Count of  free :  1\n",
      "Count of  encyclopedia :  1\n",
      "Count of  Jump :  2\n",
      "Count of  navigation :  2\n",
      "Count of  search :  3\n",
      "Count of  This :  12\n",
      "Count of  article :  4\n",
      "Count of  may :  2\n",
      "Count of  require :  2\n",
      "Count of  cleanup :  4\n",
      "Count of  meet :  1\n",
      "Count of  's :  5\n",
      "Count of  quality :  1\n",
      "Count of  standards :  2\n",
      "Count of  . :  146\n",
      "Count of  No :  2\n",
      "Count of  reason :  2\n",
      "Count of  specified :  1\n",
      "Count of  Please :  2\n",
      "Count of  help :  3\n",
      "Count of  improve :  3\n",
      "Count of  ( :  33\n",
      "Count of  June :  6\n",
      "Count of  2009 :  2\n",
      "Count of  ) :  33\n",
      "Count of  Learn :  2\n",
      "Count of  remove :  2\n",
      "Count of  template :  2\n",
      "Count of  message :  3\n",
      "Count of  application :  6\n",
      "Count of  data :  43\n",
      "Count of  techniques :  8\n",
      "Count of  discover :  4\n",
      "Count of  World :  6\n",
      "Count of  Wide :  7\n",
      "Count of  As :  3\n",
      "Count of  name :  2\n",
      "Count of  proposes :  1\n",
      "Count of  information :  17\n",
      "Count of  gathered :  1\n",
      "Count of  web :  29\n",
      "Count of  It :  4\n",
      "Count of  makes :  3\n",
      "Count of  utilization :  1\n",
      "Count of  automated :  2\n",
      "Count of  apparatuses :  1\n",
      "Count of  reveal :  2\n",
      "Count of  extricate :  1\n",
      "Count of  servers :  2\n",
      "Count of  web2 :  1\n",
      "Count of  reports :  1\n",
      "Count of  permits :  2\n",
      "Count of  organizations :  1\n",
      "Count of  get :  1\n",
      "Count of  organized :  1\n",
      "Count of  unstructured :  3\n",
      "Count of  browser :  1\n",
      "Count of  activities :  2\n",
      "Count of  server :  5\n",
      "Count of  logs :  5\n",
      "Count of  website :  2\n",
      "Count of  link :  2\n",
      "Count of  structure :  27\n",
      "Count of  page :  12\n",
      "Count of  content :  15\n",
      "Count of  different :  6\n",
      "Count of  sources :  3\n",
      "Count of  The :  21\n",
      "Count of  goal :  1\n",
      "Count of  generate :  2\n",
      "Count of  structural :  4\n",
      "Count of  summary :  1\n",
      "Count of  site :  9\n",
      "Count of  Technically :  1\n",
      "Count of  mainly :  1\n",
      "Count of  focuses :  1\n",
      "Count of  inner-document :  1\n",
      "Count of  tries :  2\n",
      "Count of  hyperlinks :  4\n",
      "Count of  inter-document :  1\n",
      "Count of  level :  3\n",
      "Count of  Based :  3\n",
      "Count of  topology :  1\n",
      "Count of  categorize :  3\n",
      "Count of  pages :  5\n",
      "Count of  similarity :  1\n",
      "Count of  relationship :  3\n",
      "Count of  sites :  2\n",
      "Count of  also :  5\n",
      "Count of  another :  1\n",
      "Count of  direction :  1\n",
      "Count of  – :  5\n",
      "Count of  discovering :  1\n",
      "Count of  document :  5\n",
      "Count of  type :  3\n",
      "Count of  used :  8\n",
      "Count of  schema :  3\n",
      "Count of  would :  1\n",
      "Count of  good :  1\n",
      "Count of  purpose :  2\n",
      "Count of  make :  3\n",
      "Count of  possible :  1\n",
      "Count of  compare/integrate :  1\n",
      "Count of  schemes :  1\n",
      "Count of  facilitate :  1\n",
      "Count of  introducing :  2\n",
      "Count of  database :  4\n",
      "Count of  accessing :  1\n",
      "Count of  providing :  2\n",
      "Count of  reference :  2\n",
      "Count of  Contents :  2\n",
      "Count of  1 :  5\n",
      "Count of  types :  4\n",
      "Count of  2 :  5\n",
      "Count of  usage :  20\n",
      "Count of  2.1 :  1\n",
      "Count of  Pros :  2\n",
      "Count of  2.2 :  1\n",
      "Count of  Cons :  2\n",
      "Count of  3 :  2\n",
      "Count of  4 :  3\n",
      "Count of  4.1 :  1\n",
      "Count of  foreign :  2\n",
      "Count of  languages :  2\n",
      "Count of  4.1.1 :  1\n",
      "Count of  Chinese :  4\n",
      "Count of  5 :  2\n",
      "Count of  See :  2\n",
      "Count of  6 :  5\n",
      "Count of  References :  2\n",
      "Count of  7 :  3\n",
      "Count of  Resources :  2\n",
      "Count of  7.1 :  1\n",
      "Count of  External :  2\n",
      "Count of  links :  7\n",
      "Count of  7.2 :  1\n",
      "Count of  Books :  2\n",
      "Count of  7.3 :  1\n",
      "Count of  Bibliographic :  2\n",
      "Count of  references :  3\n",
      "Count of  [ :  26\n",
      "Count of  edit :  14\n",
      "Count of  ] :  26\n",
      "Count of  divided :  2\n",
      "Count of  three :  1\n",
      "Count of  general :  2\n",
      "Count of  categories :  4\n",
      "Count of  objectives :  1\n",
      "Count of  Comparison :  1\n",
      "Count of  IR :  1\n",
      "Count of  view :  6\n",
      "Count of  DB :  2\n",
      "Count of  View :  3\n",
      "Count of  Unstructured :  1\n",
      "Count of  Structured :  2\n",
      "Count of  Semi-structured :  1\n",
      "Count of  Link :  3\n",
      "Count of  Interactivity :  1\n",
      "Count of  Main :  2\n",
      "Count of  Text :  2\n",
      "Count of  documents :  11\n",
      "Count of  Hypertext :  3\n",
      "Count of  Server :  3\n",
      "Count of  Browser :  1\n",
      "Count of  Representation :  1\n",
      "Count of  Bag :  1\n",
      "Count of  words :  5\n",
      "Count of  n-gram :  1\n",
      "Count of  terms :  2\n",
      "Count of  phrases :  1\n",
      "Count of  concepts :  1\n",
      "Count of  ontology :  1\n",
      "Count of  Relational :  4\n",
      "Count of  Edge :  1\n",
      "Count of  labed :  1\n",
      "Count of  graph :  5\n",
      "Count of  Graph :  2\n",
      "Count of  table :  1\n",
      "Count of  Method :  2\n",
      "Count of  Machine :  3\n",
      "Count of  learning :  2\n",
      "Count of  Statistical :  2\n",
      "Count of  including :  2\n",
      "Count of  NLP :  1\n",
      "Count of  Proprietary :  2\n",
      "Count of  algorithms :  5\n",
      "Count of  Association :  4\n",
      "Count of  rules :  3\n",
      "Count of  Application :  3\n",
      "Count of  Categorization :  2\n",
      "Count of  Clustering :  3\n",
      "Count of  Finding :  4\n",
      "Count of  extract :  2\n",
      "Count of  text :  4\n",
      "Count of  frequent :  1\n",
      "Count of  sub :  1\n",
      "Count of  structures :  3\n",
      "Count of  discovery :  2\n",
      "Count of  Site :  2\n",
      "Count of  construction :  1\n",
      "Count of  Adaptation :  1\n",
      "Count of  management :  3\n",
      "Count of  interesting :  1\n",
      "Count of  order :  2\n",
      "Count of  understand :  1\n",
      "Count of  better :  4\n",
      "Count of  serve :  1\n",
      "Count of  needs :  5\n",
      "Count of  Web-based :  1\n",
      "Count of  applications :  6\n",
      "Count of  Usage :  8\n",
      "Count of  captures :  1\n",
      "Count of  identity :  1\n",
      "Count of  origin :  1\n",
      "Count of  users :  3\n",
      "Count of  along :  1\n",
      "Count of  browsing :  2\n",
      "Count of  behavior :  2\n",
      "Count of  classified :  1\n",
      "Count of  depending :  1\n",
      "Count of  kind :  1\n",
      "Count of  considered :  3\n",
      "Count of  : :  36\n",
      "Count of  user :  10\n",
      "Count of  collected :  2\n",
      "Count of  Typical :  1\n",
      "Count of  includes :  2\n",
      "Count of  IP :  1\n",
      "Count of  address :  2\n",
      "Count of  access :  2\n",
      "Count of  time :  2\n",
      "Count of  Commercial :  1\n",
      "Count of  significant :  1\n",
      "Count of  features :  4\n",
      "Count of  enable :  1\n",
      "Count of  e-commerce :  2\n",
      "Count of  built :  1\n",
      "Count of  top :  1\n",
      "Count of  little :  1\n",
      "Count of  effort :  1\n",
      "Count of  A :  3\n",
      "Count of  key :  1\n",
      "Count of  feature :  4\n",
      "Count of  ability :  1\n",
      "Count of  track :  1\n",
      "Count of  various :  1\n",
      "Count of  kinds :  3\n",
      "Count of  business :  1\n",
      "Count of  events :  3\n",
      "Count of  log :  2\n",
      "Count of  New :  1\n",
      "Count of  defined :  3\n",
      "Count of  logging :  1\n",
      "Count of  turned :  1\n",
      "Count of  thus :  2\n",
      "Count of  generating :  1\n",
      "Count of  histories :  1\n",
      "Count of  specially :  1\n",
      "Count of  Many :  1\n",
      "Count of  end :  1\n",
      "Count of  combination :  1\n",
      "Count of  one :  4\n",
      "Count of  applied :  3\n",
      "Count of  Studies :  1\n",
      "Count of  related :  1\n",
      "Count of  work :  1\n",
      "Count of  concerned :  1\n",
      "Count of  two :  4\n",
      "Count of  areas :  1\n",
      "Count of  constraint-based :  1\n",
      "Count of  developed :  1\n",
      "Count of  software :  1\n",
      "Count of  tools :  4\n",
      "Count of  systems :  2\n",
      "Count of  Costa :  2\n",
      "Count of  Seco :  2\n",
      "Count of  demonstrated :  1\n",
      "Count of  semantic :  3\n",
      "Count of  hyponymy :  1\n",
      "Count of  relationships :  1\n",
      "Count of  particular :  4\n",
      "Count of  given :  2\n",
      "Count of  community :  1\n",
      "Count of  essentially :  2\n",
      "Count of  many :  1\n",
      "Count of  advantages :  1\n",
      "Count of  technology :  6\n",
      "Count of  attractive :  1\n",
      "Count of  corporations :  1\n",
      "Count of  government :  1\n",
      "Count of  agencies :  2\n",
      "Count of  enabled :  1\n",
      "Count of  personalized :  1\n",
      "Count of  marketing :  1\n",
      "Count of  eventually :  1\n",
      "Count of  results :  2\n",
      "Count of  higher :  2\n",
      "Count of  trade :  2\n",
      "Count of  volumes :  1\n",
      "Count of  Government :  1\n",
      "Count of  using :  3\n",
      "Count of  classify :  1\n",
      "Count of  threats :  1\n",
      "Count of  fight :  1\n",
      "Count of  terrorism :  1\n",
      "Count of  predicting :  1\n",
      "Count of  capability :  2\n",
      "Count of  benefit :  1\n",
      "Count of  society :  1\n",
      "Count of  identifying :  1\n",
      "Count of  criminal :  1\n",
      "Count of  Companies :  2\n",
      "Count of  establish :  1\n",
      "Count of  customer :  7\n",
      "Count of  understanding :  1\n",
      "Count of  reacting :  1\n",
      "Count of  faster :  1\n",
      "Count of  find :  3\n",
      "Count of  attract :  1\n",
      "Count of  retain :  2\n",
      "Count of  customers :  3\n",
      "Count of  ; :  17\n",
      "Count of  save :  1\n",
      "Count of  production :  1\n",
      "Count of  costs :  1\n",
      "Count of  utilizing :  1\n",
      "Count of  acquired :  1\n",
      "Count of  insight :  1\n",
      "Count of  requirements :  1\n",
      "Count of  They :  3\n",
      "Count of  increase :  1\n",
      "Count of  profitability :  1\n",
      "Count of  target :  2\n",
      "Count of  pricing :  1\n",
      "Count of  based :  4\n",
      "Count of  profiles :  3\n",
      "Count of  created :  1\n",
      "Count of  even :  1\n",
      "Count of  might :  6\n",
      "Count of  default :  1\n",
      "Count of  competitor :  1\n",
      "Count of  company :  2\n",
      "Count of  try :  1\n",
      "Count of  promotional :  1\n",
      "Count of  offers :  1\n",
      "Count of  specific :  4\n",
      "Count of  reducing :  1\n",
      "Count of  risk :  1\n",
      "Count of  losing :  1\n",
      "Count of  More :  2\n",
      "Count of  benefits :  2\n",
      "Count of  particularly :  1\n",
      "Count of  area :  1\n",
      "Count of  personalization :  3\n",
      "Count of  outlined :  1\n",
      "Count of  frameworks :  1\n",
      "Count of  probabilistic :  1\n",
      "Count of  latent :  1\n",
      "Count of  analysis :  3\n",
      "Count of  model :  2\n",
      "Count of  offer :  1\n",
      "Count of  additional :  3\n",
      "Count of  pattern :  2\n",
      "Count of  process :  2\n",
      "Count of  provides :  1\n",
      "Count of  relevant :  1\n",
      "Count of  collaborative :  1\n",
      "Count of  recommendation :  1\n",
      "Count of  These :  3\n",
      "Count of  models :  1\n",
      "Count of  demonstrate :  1\n",
      "Count of  problems :  1\n",
      "Count of  associated :  1\n",
      "Count of  traditional :  2\n",
      "Count of  biases :  1\n",
      "Count of  questions :  1\n",
      "Count of  regarding :  1\n",
      "Count of  validity :  2\n",
      "Count of  since :  1\n",
      "Count of  obtained :  6\n",
      "Count of  subjective :  1\n",
      "Count of  degrade :  1\n",
      "Count of  There :  2\n",
      "Count of  elements :  1\n",
      "Count of  unique :  1\n",
      "Count of  show :  1\n",
      "Count of  include :  1\n",
      "Count of  way :  1\n",
      "Count of  knowledge :  4\n",
      "Count of  interpreting :  1\n",
      "Count of  analyzing :  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of  reasoning :  1\n",
      "Count of  phase :  1\n",
      "Count of  create :  1\n",
      "Count of  issues :  2\n",
      "Count of  personal :  4\n",
      "Count of  nature :  1\n",
      "Count of  cause :  1\n",
      "Count of  concerns :  1\n",
      "Count of  criticized :  1\n",
      "Count of  ethical :  2\n",
      "Count of  issue :  1\n",
      "Count of  involving :  1\n",
      "Count of  invasion :  1\n",
      "Count of  privacy :  3\n",
      "Count of  Privacy :  5\n",
      "Count of  lost :  1\n",
      "Count of  concerning :  1\n",
      "Count of  individual :  4\n",
      "Count of  disseminated :  1\n",
      "Count of  especially :  1\n",
      "Count of  occurs :  1\n",
      "Count of  without :  3\n",
      "Count of  consent :  1\n",
      "Count of  analyzed :  1\n",
      "Count of  clustered :  1\n",
      "Count of  form :  1\n",
      "Count of  made :  2\n",
      "Count of  anonymous :  3\n",
      "Count of  clustering :  1\n",
      "Count of  Thus :  1\n",
      "Count of  de-individualize :  1\n",
      "Count of  judging :  2\n",
      "Count of  mouse :  1\n",
      "Count of  clicks :  1\n",
      "Count of  De-individualization :  1\n",
      "Count of  tendency :  1\n",
      "Count of  treating :  1\n",
      "Count of  people :  1\n",
      "Count of  basis :  1\n",
      "Count of  group :  1\n",
      "Count of  characteristics :  2\n",
      "Count of  instead :  1\n",
      "Count of  merits :  2\n",
      "Count of  Another :  1\n",
      "Count of  important :  2\n",
      "Count of  concern :  1\n",
      "Count of  companies :  3\n",
      "Count of  collecting :  1\n",
      "Count of  use :  5\n",
      "Count of  totally :  1\n",
      "Count of  purposes :  1\n",
      "Count of  violates :  1\n",
      "Count of  interests :  1\n",
      "Count of  growing :  1\n",
      "Count of  trend :  2\n",
      "Count of  selling :  1\n",
      "Count of  commodity :  1\n",
      "Count of  encourages :  1\n",
      "Count of  owners :  1\n",
      "Count of  increased :  1\n",
      "Count of  amount :  1\n",
      "Count of  captured :  1\n",
      "Count of  traded :  1\n",
      "Count of  increasing :  1\n",
      "Count of  likeliness :  1\n",
      "Count of  invaded :  1\n",
      "Count of  buy :  1\n",
      "Count of  obliged :  1\n",
      "Count of  authors :  1\n",
      "Count of  release :  3\n",
      "Count of  legally :  1\n",
      "Count of  responsible :  1\n",
      "Count of  contents :  1\n",
      "Count of  inaccuracies :  1\n",
      "Count of  result :  3\n",
      "Count of  serious :  1\n",
      "Count of  lawsuits :  1\n",
      "Count of  law :  1\n",
      "Count of  preventing :  1\n",
      "Count of  trading :  1\n",
      "Count of  Some :  1\n",
      "Count of  controversial :  2\n",
      "Count of  attributes :  3\n",
      "Count of  like :  1\n",
      "Count of  sex :  1\n",
      "Count of  race :  2\n",
      "Count of  religion :  2\n",
      "Count of  sexual :  2\n",
      "Count of  orientation :  2\n",
      "Count of  individuals :  1\n",
      "Count of  practices :  1\n",
      "Count of  anti-discrimination :  1\n",
      "Count of  legislation :  1\n",
      "Count of  hard :  1\n",
      "Count of  identify :  3\n",
      "Count of  strong :  1\n",
      "Count of  rule :  1\n",
      "Count of  could :  1\n",
      "Count of  denial :  1\n",
      "Count of  service :  1\n",
      "Count of  privilege :  1\n",
      "Count of  situation :  1\n",
      "Count of  avoided :  1\n",
      "Count of  high :  1\n",
      "Count of  maintained :  1\n",
      "Count of  traced :  1\n",
      "Count of  back :  1\n",
      "Count of  look :  1\n",
      "Count of  poses :  1\n",
      "Count of  threat :  1\n",
      "Count of  however :  1\n",
      "Count of  inferred :  1\n",
      "Count of  combining :  1\n",
      "Count of  separate :  1\n",
      "Count of  unscrupulous :  1\n",
      "Count of  section :  2\n",
      "Count of  expansion :  1\n",
      "Count of  You :  1\n",
      "Count of  adding :  1\n",
      "Count of  2015 :  1\n",
      "Count of  uses :  1\n",
      "Count of  theory :  1\n",
      "Count of  analyze :  1\n",
      "Count of  node :  5\n",
      "Count of  connection :  1\n",
      "Count of  According :  1\n",
      "Count of  Extracting :  1\n",
      "Count of  hyperlink :  2\n",
      "Count of  component :  2\n",
      "Count of  connects :  1\n",
      "Count of  location :  1\n",
      "Count of  Mining :  20\n",
      "Count of  tree-like :  1\n",
      "Count of  describe :  1\n",
      "Count of  HTML :  3\n",
      "Count of  XML :  1\n",
      "Count of  tag :  1\n",
      "Count of  terminology :  1\n",
      "Count of  directed :  1\n",
      "Count of  representing :  1\n",
      "Count of  edge :  1\n",
      "Count of  degree :  2\n",
      "Count of  number :  3\n",
      "Count of  pointing :  2\n",
      "Count of  generated :  1\n",
      "Count of  Techniques :  2\n",
      "Count of  PageRank :  1\n",
      "Count of  algorithm :  3\n",
      "Count of  Google :  1\n",
      "Count of  rank :  2\n",
      "Count of  Google-founder :  1\n",
      "Count of  Larry :  1\n",
      "Count of  Page :  1\n",
      "Count of  decided :  1\n",
      "Count of  extraction :  2\n",
      "Count of  integration :  1\n",
      "Count of  useful :  3\n",
      "Count of  heterogeneity :  1\n",
      "Count of  lack :  1\n",
      "Count of  much :  1\n",
      "Count of  ever-expanding :  1\n",
      "Count of  hypertext :  1\n",
      "Count of  organization :  3\n",
      "Count of  indexing :  1\n",
      "Count of  Internet :  2\n",
      "Count of  Lycos :  1\n",
      "Count of  Alta :  1\n",
      "Count of  Vista :  1\n",
      "Count of  WebCrawler :  1\n",
      "Count of  Aliweb :  1\n",
      "Count of  MetaCrawler :  1\n",
      "Count of  others :  1\n",
      "Count of  provide :  3\n",
      "Count of  comfort :  1\n",
      "Count of  generally :  1\n",
      "Count of  filter :  1\n",
      "Count of  interpret :  1\n",
      "Count of  factors :  1\n",
      "Count of  prompted :  1\n",
      "Count of  researchers :  1\n",
      "Count of  develop :  1\n",
      "Count of  intelligent :  2\n",
      "Count of  retrieval :  2\n",
      "Count of  agents :  1\n",
      "Count of  well :  1\n",
      "Count of  extend :  1\n",
      "Count of  semi-structured :  3\n",
      "Count of  available :  2\n",
      "Count of  agent-based :  1\n",
      "Count of  approach :  1\n",
      "Count of  involves :  1\n",
      "Count of  development :  1\n",
      "Count of  sophisticated :  1\n",
      "Count of  AI :  1\n",
      "Count of  act :  1\n",
      "Count of  autonomously :  1\n",
      "Count of  semi-autonomously :  1\n",
      "Count of  behalf :  1\n",
      "Count of  organize :  1\n",
      "Count of  web-based :  1\n",
      "Count of  differentiated :  1\n",
      "Count of  points :  1\n",
      "Count of  8 :  1\n",
      "Count of  Information :  6\n",
      "Count of  Retrieval :  1\n",
      "Count of  Database :  1\n",
      "Count of  9 :  1\n",
      "Count of  summarized :  1\n",
      "Count of  research :  1\n",
      "Count of  works :  2\n",
      "Count of  done :  1\n",
      "Count of  shows :  1\n",
      "Count of  researches :  1\n",
      "Count of  bag :  1\n",
      "Count of  statistics :  1\n",
      "Count of  single :  2\n",
      "Count of  isolation :  1\n",
      "Count of  represent :  2\n",
      "Count of  take :  1\n",
      "Count of  word :  2\n",
      "Count of  found :  1\n",
      "Count of  training :  1\n",
      "Count of  corpus :  1\n",
      "Count of  For :  1\n",
      "Count of  utilize :  1\n",
      "Count of  inside :  1\n",
      "Count of  utilized :  1\n",
      "Count of  representation :  2\n",
      "Count of  querying :  1\n",
      "Count of  always :  1\n",
      "Count of  infer :  1\n",
      "Count of  transform :  2\n",
      "Count of  become :  1\n",
      "Count of  several :  1\n",
      "Count of  ways :  1\n",
      "Count of  vector :  2\n",
      "Count of  space :  2\n",
      "Count of  typically :  1\n",
      "Count of  constitute :  1\n",
      "Count of  whole :  1\n",
      "Count of  realize :  1\n",
      "Count of  importance :  1\n",
      "Count of  To :  1\n",
      "Count of  resolve :  1\n",
      "Count of  tf-idf :  1\n",
      "Count of  Term :  1\n",
      "Count of  Frequency :  2\n",
      "Count of  Times :  1\n",
      "Count of  Inverse :  1\n",
      "Count of  Document :  1\n",
      "Count of  introduced :  1\n",
      "Count of  By :  2\n",
      "Count of  multi-scanning :  1\n",
      "Count of  implement :  1\n",
      "Count of  selection :  1\n",
      "Count of  Under :  1\n",
      "Count of  condition :  1\n",
      "Count of  category :  1\n",
      "Count of  rarely :  1\n",
      "Count of  affected :  1\n",
      "Count of  subset :  1\n",
      "Count of  needed :  1\n",
      "Count of  construct :  1\n",
      "Count of  evaluating :  1\n",
      "Count of  function :  1\n",
      "Count of  evaluate :  1\n",
      "Count of  set :  1\n",
      "Count of  gain :  1\n",
      "Count of  cross :  1\n",
      "Count of  entropy :  1\n",
      "Count of  mutual :  1\n",
      "Count of  odds :  1\n",
      "Count of  ratio :  1\n",
      "Count of  usually :  1\n",
      "Count of  classifier :  1\n",
      "Count of  methods :  1\n",
      "Count of  similar :  1\n",
      "Count of  usual :  1\n",
      "Count of  evaluative :  1\n",
      "Count of  classification :  1\n",
      "Count of  accuracy :  1\n",
      "Count of  precision :  1\n",
      "Count of  recall :  1\n",
      "Count of  score :  1\n",
      "Count of  pipeline :  1\n",
      "Count of  portals :  1\n",
      "Count of  confirmation :  1\n",
      "Count of  verification :  1\n",
      "Count of  integrity :  1\n",
      "Count of  building :  1\n",
      "Count of  taxonomies :  1\n",
      "Count of  generation :  1\n",
      "Count of  opinion :  1\n",
      "Count of  10 :  1\n",
      "Count of  language :  1\n",
      "Count of  code :  4\n",
      "Count of  complicated :  1\n",
      "Count of  compared :  1\n",
      "Count of  English :  1\n",
      "Count of  GB :  1\n",
      "Count of  Big5 :  1\n",
      "Count of  HZ :  1\n",
      "Count of  common :  1\n",
      "Count of  codes :  1\n",
      "Count of  Before :  1\n",
      "Count of  standard :  1\n",
      "Count of  inner :  1\n",
      "Count of  intelligence :  1\n",
      "Count of  analytics :  1\n",
      "Count of  scraping :  2\n",
      "Count of  Data :  16\n",
      "Count of  ^ :  10\n",
      "Count of  Galitsky :  2\n",
      "Count of  B. :  5\n",
      "Count of  Dobrocsi :  2\n",
      "Count of  G. :  2\n",
      "Count of  de :  3\n",
      "Count of  la :  2\n",
      "Count of  Rosa :  2\n",
      "Count of  J. :  2\n",
      "Count of  L. :  2\n",
      "Count of  Kuznetsov :  2\n",
      "Count of  S. :  1\n",
      "Count of  O.. :  1\n",
      "Count of  Using :  3\n",
      "Count of  generalization :  2\n",
      "Count of  syntactic :  2\n",
      "Count of  parse :  2\n",
      "Count of  trees :  2\n",
      "Count of  taxonomy :  2\n",
      "Count of  capture :  2\n",
      "Count of  ICCS :  2\n",
      "Count of  2011 :  2\n",
      "Count of  8323 :  2\n",
      "Count of  Weichbroth :  2\n",
      "Count of  et :  1\n",
      "Count of  al :  1\n",
      "Count of  Ngu :  1\n",
      "Count of  Anne :  1\n",
      "Count of  Kitsuregawa :  1\n",
      "Count of  Masaru :  1\n",
      "Count of  Chung :  1\n",
      "Count of  Jen-Yao :  1\n",
      "Count of  Neuhold :  1\n",
      "Count of  Erich :  1\n",
      "Count of  Sheng :  1\n",
      "Count of  Quan :  1\n",
      "Count of  2005 :  6\n",
      "Count of  Systems :  2\n",
      "Count of  Engineering :  1\n",
      "Count of  WISE :  1\n",
      "Count of  Berlin :  2\n",
      "Count of  Springer :  5\n",
      "Count of  p. :  3\n",
      "Count of  15 :  1\n",
      "Count of  ISBN :  3\n",
      "Count of  9783540300175 :  1\n",
      "Count of  Bauknecht :  1\n",
      "Count of  Kurt :  1\n",
      "Count of  Madria :  1\n",
      "Count of  Sanjay :  1\n",
      "Count of  Pernul :  1\n",
      "Count of  Gunther :  1\n",
      "Count of  2000 :  5\n",
      "Count of  Electronic :  1\n",
      "Count of  Commerce :  1\n",
      "Count of  Technologies :  1\n",
      "Count of  First :  1\n",
      "Count of  International :  3\n",
      "Count of  Conference :  3\n",
      "Count of  EC-Web :  1\n",
      "Count of  London :  1\n",
      "Count of  UK :  1\n",
      "Count of  September :  3\n",
      "Count of  4-6 :  1\n",
      "Count of  Proceedings :  4\n",
      "Count of  165 :  1\n",
      "Count of  978-3540679813 :  1\n",
      "Count of  Scime :  1\n",
      "Count of  Anthony :  1\n",
      "Count of  Applications :  2\n",
      "Count of  Hershey :  1\n",
      "Count of  PA :  1\n",
      "Count of  Idea :  2\n",
      "Count of  Group :  2\n",
      "Count of  Publishing :  1\n",
      "Count of  pp :  6\n",
      "Count of  282 :  1\n",
      "Count of  978-1591404149 :  1\n",
      "Count of  b :  1\n",
      "Count of  c :  1\n",
      "Count of  Lita :  1\n",
      "Count of  van :  1\n",
      "Count of  Wel :  1\n",
      "Count of  & :  2\n",
      "Count of  Lambèr :  1\n",
      "Count of  Royakkers :  1\n",
      "Count of  2004 :  4\n",
      "Count of  `` :  15\n",
      "Count of  Ethical :  2\n",
      "Count of  '' :  19\n",
      "Count of  PDF :  2\n",
      "Count of  Issues :  3\n",
      "Count of  Mining.. :  2\n",
      "Count of  Kirsten :  1\n",
      "Count of  Maelstrom :  1\n",
      "Count of  John :  1\n",
      "Count of  F. :  2\n",
      "Count of  Rodrick :  1\n",
      "Count of  Vladimir :  1\n",
      "Count of  Estivill-Castro :  1\n",
      "Count of  Denise :  1\n",
      "Count of  Vries :  1\n",
      "Count of  2007 :  4\n",
      "Count of  Legal :  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of  Technical :  2\n",
      "Count of  Preservation :  2\n",
      "Count of  Wang :  2\n",
      "Count of  Yan :  1\n",
      "Count of  Knowledge :  4\n",
      "Count of  Discovery :  5\n",
      "Count of  Patterns :  5\n",
      "Count of  Kosala :  1\n",
      "Count of  Raymond :  1\n",
      "Count of  Hendrik :  1\n",
      "Count of  Blockeel :  1\n",
      "Count of  July :  1\n",
      "Count of  Research :  2\n",
      "Count of  Survey :  1\n",
      "Count of  SIGKDD :  1\n",
      "Count of  Explorations :  1\n",
      "Count of  arXiv :  1\n",
      "Count of  cs.LG/0011033 :  1\n",
      "Count of  B :  1\n",
      "Count of  G :  1\n",
      "Count of  JL :  1\n",
      "Count of  SO :  1\n",
      "Count of  list :  1\n",
      "Count of  remain :  1\n",
      "Count of  unclear :  1\n",
      "Count of  insufficient :  1\n",
      "Count of  inline :  1\n",
      "Count of  citations :  4\n",
      "Count of  precise :  1\n",
      "Count of  Future :  1\n",
      "Count of  Sites :  1\n",
      "Count of  = :  1\n",
      "Count of  Services :  1\n",
      "Count of  Zdravko :  1\n",
      "Count of  Markov :  1\n",
      "Count of  Daniel :  4\n",
      "Count of  T. :  2\n",
      "Count of  Larose :  1\n",
      "Count of  Uncovering :  1\n",
      "Count of  Content :  1\n",
      "Count of  Structure :  1\n",
      "Count of  Wiley :  1\n",
      "Count of  Jesus :  1\n",
      "Count of  Mena :  1\n",
      "Count of  Your :  1\n",
      "Count of  Website :  2\n",
      "Count of  Digital :  1\n",
      "Count of  Press :  2\n",
      "Count of  1999 :  3\n",
      "Count of  Soumen :  1\n",
      "Count of  Chakrabarti :  1\n",
      "Count of  Analysis :  5\n",
      "Count of  Semi :  1\n",
      "Count of  Morgan :  1\n",
      "Count of  Kaufmann :  1\n",
      "Count of  2002 :  1\n",
      "Count of  Bing :  2\n",
      "Count of  Liu :  2\n",
      "Count of  Exploring :  1\n",
      "Count of  Hyperlinks :  1\n",
      "Count of  Advances :  1\n",
      "Count of  revised :  2\n",
      "Count of  papers :  2\n",
      "Count of  th :  2\n",
      "Count of  workshop :  2\n",
      "Count of  Olfa :  2\n",
      "Count of  Nasraoui :  5\n",
      "Count of  Osmar :  1\n",
      "Count of  Zaiane :  1\n",
      "Count of  Myra :  1\n",
      "Count of  Spiliopoulou :  1\n",
      "Count of  Bamshad :  2\n",
      "Count of  Mobasher :  6\n",
      "Count of  Philip :  1\n",
      "Count of  Yu :  1\n",
      "Count of  Brij :  2\n",
      "Count of  Masand :  2\n",
      "Count of  Eds. :  2\n",
      "Count of  Lecture :  2\n",
      "Count of  Notes :  2\n",
      "Count of  Artificial :  4\n",
      "Count of  Intelligence :  4\n",
      "Count of  LNAI :  1\n",
      "Count of  4198 :  1\n",
      "Count of  2006 :  5\n",
      "Count of  Mike :  1\n",
      "Count of  Thelwall :  1\n",
      "Count of  An :  1\n",
      "Count of  Science :  1\n",
      "Count of  Approach :  1\n",
      "Count of  Academic :  1\n",
      "Count of  Baraglia :  1\n",
      "Count of  R. :  6\n",
      "Count of  Silvestri :  1\n",
      "Count of  Dynamic :  1\n",
      "Count of  intervention :  1\n",
      "Count of  In :  3\n",
      "Count of  Communications :  2\n",
      "Count of  ACM :  3\n",
      "Count of  50 :  1\n",
      "Count of  63-67 :  1\n",
      "Count of  Cooley :  3\n",
      "Count of  Srivastave :  1\n",
      "Count of  J :  3\n",
      "Count of  1997 :  1\n",
      "Count of  “ :  10\n",
      "Count of  Pattern :  2\n",
      "Count of  ” :  10\n",
      "Count of  9th :  1\n",
      "Count of  IEEE :  1\n",
      "Count of  Tool :  1\n",
      "Count of  Srivastava :  2\n",
      "Count of  Preparation :  1\n",
      "Count of  Browsing :  2\n",
      "Count of  Journal :  2\n",
      "Count of  System :  1\n",
      "Count of  Vol.1 :  1\n",
      "Count of  Issue :  2\n",
      "Count of  5–32 :  1\n",
      "Count of  RP :  1\n",
      "Count of  N. :  1\n",
      "Count of  Hyponymy :  1\n",
      "Count of  Extraction :  1\n",
      "Count of  Search :  2\n",
      "Count of  Behavior :  1\n",
      "Count of  On :  1\n",
      "Count of  Query :  1\n",
      "Count of  Reformulation :  1\n",
      "Count of  11th :  1\n",
      "Count of  Ibero-American :  1\n",
      "Count of  2008 :  1\n",
      "Count of  October :  1\n",
      "Count of  Kohavi :  1\n",
      "Count of  Mason :  1\n",
      "Count of  Zheng :  1\n",
      "Count of  Z :  1\n",
      "Count of  Lessons :  1\n",
      "Count of  Challenges :  1\n",
      "Count of  Retail :  1\n",
      "Count of  E-commerce :  1\n",
      "Count of  Learning :  1\n",
      "Count of  Vol :  3\n",
      "Count of  57 :  1\n",
      "Count of  83–113 :  1\n",
      "Count of  Lillian :  1\n",
      "Count of  Clark :  1\n",
      "Count of  I-Hsien :  3\n",
      "Count of  Ting :  3\n",
      "Count of  Chris :  3\n",
      "Count of  Kimble :  3\n",
      "Count of  Peter :  1\n",
      "Count of  Wright :  1\n",
      "Count of  Kudenko :  3\n",
      "Count of  Combining :  2\n",
      "Count of  ethnographic :  1\n",
      "Count of  clickstream :  1\n",
      "Count of  strategies :  1\n",
      "Count of  11 :  1\n",
      "Count of  January :  2\n",
      "Count of  Eirinaki :  1\n",
      "Count of  M. :  5\n",
      "Count of  Vazirgiannis :  1\n",
      "Count of  2003 :  5\n",
      "Count of  Personalization :  5\n",
      "Count of  Transactions :  1\n",
      "Count of  Technology :  1\n",
      "Count of  Vol.3 :  1\n",
      "Count of  No.1 :  1\n",
      "Count of  February :  1\n",
      "Count of  Automatic :  1\n",
      "Count of  43 :  1\n",
      "Count of  No.8 :  1\n",
      "Count of  142–151 :  1\n",
      "Count of  Dai :  1\n",
      "Count of  H. :  2\n",
      "Count of  Luo :  1\n",
      "Count of  Nakagawa :  1\n",
      "Count of  2001 :  2\n",
      "Count of  Effective :  2\n",
      "Count of  Rule :  1\n",
      "Count of  Discover :  1\n",
      "Count of  WIDM :  1\n",
      "Count of  Atlanta :  1\n",
      "Count of  GA :  1\n",
      "Count of  USA :  1\n",
      "Count of  9–15 :  1\n",
      "Count of  O. :  3\n",
      "Count of  Petenes :  1\n",
      "Count of  C. :  3\n",
      "Count of  Fuzzy :  3\n",
      "Count of  Inference :  1\n",
      "Count of  Proc :  1\n",
      "Count of  WebKDD :  1\n",
      "Count of  KDD :  1\n",
      "Count of  Workshop :  1\n",
      "Count of  Premise :  1\n",
      "Count of  Intelligent :  1\n",
      "Count of  Washington :  1\n",
      "Count of  DC :  1\n",
      "Count of  August :  2\n",
      "Count of  37 :  1\n",
      "Count of  Frigui :  1\n",
      "Count of  Joshi :  1\n",
      "Count of  A. :  1\n",
      "Count of  Krishnapuram :  1\n",
      "Count of  Access :  1\n",
      "Count of  Logs :  1\n",
      "Count of  Competitive :  1\n",
      "Count of  Eighth :  1\n",
      "Count of  Congress :  1\n",
      "Count of  Hsinchu :  1\n",
      "Count of  Taiwan :  1\n",
      "Count of  Invited :  1\n",
      "Count of  chapter :  1\n",
      "Count of  Encyclopedia :  1\n",
      "Count of  Warehousing :  1\n",
      "Count of  Ed :  1\n",
      "Count of  Pierrakos :  1\n",
      "Count of  D. :  2\n",
      "Count of  Paliouras :  1\n",
      "Count of  Papatheodorou :  1\n",
      "Count of  Spyropoulos :  1\n",
      "Count of  tool :  1\n",
      "Count of  survey :  1\n",
      "Count of  User :  2\n",
      "Count of  modelling :  1\n",
      "Count of  adapted :  1\n",
      "Count of  interaction :  1\n",
      "Count of  journal :  1\n",
      "Count of  Vol.13 :  1\n",
      "Count of  311–372 :  1\n",
      "Count of  Restore :  1\n",
      "Count of  Restoring :  1\n",
      "Count of  Missing :  1\n",
      "Count of  Side :  1\n",
      "Count of  Clickstream :  2\n",
      "Count of  UBB :  1\n",
      "Count of  Unexpected :  1\n",
      "Count of  Behaviour :  1\n",
      "Count of  ’ :  1\n",
      "Count of  Design :  1\n",
      "Count of  P. :  1\n",
      "Count of  Owoc :  1\n",
      "Count of  Pleszkun :  1\n",
      "Count of  2012 :  1\n",
      "Count of  Navigation :  3\n",
      "Count of  WWW :  1\n",
      "Count of  Log :  1\n",
      "Count of  Files :  1\n",
      "Count of  Retrieved :  1\n",
      "Count of  https :  1\n",
      "Count of  //en.wikipedia.org/w/index.php :  1\n",
      "Count of  ? :  1\n",
      "Count of  title=Web_mining :  1\n",
      "Count of  oldid=933573148 :  1\n",
      "Count of  Categories :  1\n",
      "Count of  analyticsData :  1\n",
      "Count of  miningWorld :  1\n",
      "Count of  WebHidden :  1\n",
      "Count of  Articles :  1\n",
      "Count of  needing :  3\n",
      "Count of  2009All :  2\n",
      "Count of  cleanupCleanup :  1\n",
      "Count of  tagged :  1\n",
      "Count of  articles :  3\n",
      "Count of  field :  1\n",
      "Count of  2009Wikipedia :  1\n",
      "Count of  2009Articles :  1\n",
      "Count of  expanded :  1\n",
      "Count of  2015All :  1\n",
      "Count of  expandedArticles :  1\n",
      "Count of  small :  1\n",
      "Count of  boxesArticles :  1\n",
      "Count of  lacking :  2\n",
      "Count of  in-text :  2\n",
      "Count of  menu :  1\n",
      "Count of  Personal :  1\n",
      "Count of  Not :  1\n",
      "Count of  logged :  1\n",
      "Count of  inTalkContributionsCreate :  1\n",
      "Count of  accountLog :  1\n",
      "Count of  Namespaces :  1\n",
      "Count of  ArticleTalk :  1\n",
      "Count of  Variants :  1\n",
      "Count of  Views :  1\n",
      "Count of  ReadEditView :  1\n",
      "Count of  history :  1\n",
      "Count of  pageContentsFeatured :  1\n",
      "Count of  contentCurrent :  1\n",
      "Count of  eventsRandom :  1\n",
      "Count of  articleDonate :  1\n",
      "Count of  WikipediaWikipedia :  1\n",
      "Count of  store :  1\n",
      "Count of  Interaction :  1\n",
      "Count of  HelpAbout :  1\n",
      "Count of  WikipediaCommunity :  1\n",
      "Count of  portalRecent :  1\n",
      "Count of  changesContact :  1\n",
      "Count of  Tools :  1\n",
      "Count of  What :  1\n",
      "Count of  hereRelated :  1\n",
      "Count of  changesUpload :  1\n",
      "Count of  fileSpecial :  1\n",
      "Count of  pagesPermanent :  1\n",
      "Count of  linkPage :  1\n",
      "Count of  informationWikidata :  1\n",
      "Count of  itemCite :  1\n",
      "Count of  Print/export :  1\n",
      "Count of  Create :  1\n",
      "Count of  bookDownload :  1\n",
      "Count of  PDFPrintable :  1\n",
      "Count of  version :  1\n",
      "Count of  Languages :  1\n",
      "Count of  العربيةDeutschEspañolEuskaraفارسیFrançais한국어हिन्दीHrvatskiMagyar日本語PortuguêsРусскийSlovenčinaไทย :  1\n",
      "Count of  Edit :  1\n",
      "Count of  last :  1\n",
      "Count of  edited :  1\n",
      "Count of  2020 :  1\n",
      "Count of  20:51 :  1\n",
      "Count of  UTC :  1\n",
      "Count of  Creative :  1\n",
      "Count of  Commons :  1\n",
      "Count of  Attribution-ShareAlike :  1\n",
      "Count of  License :  1\n",
      "Count of  apply :  1\n",
      "Count of  agree :  1\n",
      "Count of  Terms :  1\n",
      "Count of  Use :  1\n",
      "Count of  Policy :  1\n",
      "Count of  Wikipedia® :  1\n",
      "Count of  registered :  1\n",
      "Count of  trademark :  1\n",
      "Count of  Wikimedia :  1\n",
      "Count of  Foundation :  1\n",
      "Count of  Inc. :  1\n",
      "Count of  non-profit :  1\n",
      "Count of  policy :  1\n",
      "Count of  About :  1\n",
      "Count of  Disclaimers :  1\n",
      "Count of  Contact :  1\n",
      "Count of  Developers :  1\n",
      "Count of  Statistics :  1\n",
      "Count of  Cookie :  1\n",
      "Count of  statement :  1\n",
      "Count of  Mobile :  1\n"
     ]
    }
   ],
   "source": [
    "for i in term_count.keys():\n",
    "    print(\"Count of \", i, \": \", term_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get(\"https://en.wikipedia.org/wiki/Web_mining\")\n",
    "soup = BeautifulSoup(url.text)\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.decompose()\n",
    "text = soup.get_text()\n",
    "lines = (line.strip() for line in text.splitlines())\n",
    "# break multi-headlines into a line each\n",
    "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# drop blank lines\n",
    "text = '\\n'.join(chunk for chunk in chunks if chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('to', 'TO')]\n",
      "[('to', 'TO')]\n",
      "[('has', 'VBZ')]\n",
      "[('been', 'VBN')]\n",
      "[('this', 'DT')]\n",
      "[('if', 'IN')]\n",
      "[('you', 'PRP')]\n",
      "[('can', 'MD')]\n",
      "[('how', 'WRB')]\n",
      "[('and', 'CC')]\n",
      "[('when', 'WRB')]\n",
      "[('to', 'TO')]\n",
      "[('this', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('patterns', 'NNS')]\n",
      "[('from', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('this', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('it', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('to', 'TO')]\n",
      "[('both', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('about', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('while', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('at', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('will', 'MD')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('such', 'JJ')]\n",
      "[('as', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('between', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('have', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('itself', 'PRP')]\n",
      "[('of', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('this', 'DT')]\n",
      "[('be', 'VB')]\n",
      "[('for', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('it', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('of', 'IN')]\n",
      "[('will', 'MD')]\n",
      "[('for', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('by', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('into', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('between', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('as', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('or', 'CC')]\n",
      "[('patterns', 'NNS')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('patterns', 'NNS')]\n",
      "[('from', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('or', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('with', 'IN')]\n",
      "[('their', 'PRP$')]\n",
      "[('at', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('itself', 'PRP')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('further', 'RB')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('are', 'VBP')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('have', 'VB')]\n",
      "[('to', 'TO')]\n",
      "[('to', 'TO')]\n",
      "[('be', 'VB')]\n",
      "[('on', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('them', 'PRP')]\n",
      "[('with', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('them', 'PRP')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('in', 'IN')]\n",
      "[('an', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('on', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('them', 'PRP')]\n",
      "[('of', 'IN')]\n",
      "[('these', 'DT')]\n",
      "[('a', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('or', 'CC')]\n",
      "[('more', 'RBR')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('above', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('are', 'VBP')]\n",
      "[('with', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('that', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('to', 'TO')]\n",
      "[('in', 'IN')]\n",
      "[('about', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('a', 'DT')]\n",
      "[('has', 'VBZ')]\n",
      "[('which', 'WDT')]\n",
      "[('this', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('has', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('do', 'VB')]\n",
      "[('which', 'WDT')]\n",
      "[('in', 'IN')]\n",
      "[('are', 'VBP')]\n",
      "[('this', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('against', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('by', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('to', 'TO')]\n",
      "[('can', 'MD')]\n",
      "[('and', 'CC')]\n",
      "[('they', 'PRP')]\n",
      "[('can', 'MD')]\n",
      "[('on', 'IN')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('by', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('can', 'MD')]\n",
      "[('who', 'WP')]\n",
      "[('to', 'TO')]\n",
      "[('a', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('will', 'MD')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('by', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('or', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('are', 'VBP')]\n",
      "[('in', 'IN')]\n",
      "[('such', 'JJ')]\n",
      "[('as', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('which', 'WDT')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('is', 'VBZ')]\n",
      "[('because', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('with', 'IN')]\n",
      "[('more', 'RBR')]\n",
      "[('through', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('with', 'IN')]\n",
      "[('such', 'JJ')]\n",
      "[('as', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('patterns', 'NNS')]\n",
      "[('are', 'VBP')]\n",
      "[('not', 'RB')]\n",
      "[('and', 'CC')]\n",
      "[('do', 'VB')]\n",
      "[('not', 'RB')]\n",
      "[('over', 'IN')]\n",
      "[('are', 'VBP')]\n",
      "[('to', 'TO')]\n",
      "[('that', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('these', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('when', 'WRB')]\n",
      "[('and', 'CC')]\n",
      "[('about', 'IN')]\n",
      "[('patterns', 'NNS')]\n",
      "[('during', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('by', 'IN')]\n",
      "[('itself', 'PRP')]\n",
      "[('does', 'VBZ')]\n",
      "[('not', 'RB')]\n",
      "[('but', 'CC')]\n",
      "[('this', 'DT')]\n",
      "[('when', 'WRB')]\n",
      "[('on', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('most', 'JJS')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('when', 'WRB')]\n",
      "[('an', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('or', 'CC')]\n",
      "[('if', 'IN')]\n",
      "[('this', 'DT')]\n",
      "[('their', 'PRP$')]\n",
      "[('or', 'CC')]\n",
      "[('will', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('and', 'CC')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('will', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('before', 'IN')]\n",
      "[('so', 'RB')]\n",
      "[('that', 'IN')]\n",
      "[('there', 'RB')]\n",
      "[('are', 'VBP')]\n",
      "[('no', 'DT')]\n",
      "[('these', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('by', 'IN')]\n",
      "[('them', 'PRP')]\n",
      "[('by', 'IN')]\n",
      "[('their', 'PRP$')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('as', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('their', 'PRP$')]\n",
      "[('own', 'JJ')]\n",
      "[('and', 'CC')]\n",
      "[('is', 'VBZ')]\n",
      "[('that', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('for', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('for', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('this', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('as', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('from', 'IN')]\n",
      "[('their', 'PRP$')]\n",
      "[('has', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('being', 'VBG')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('being', 'VBG')]\n",
      "[('which', 'WDT')]\n",
      "[('the', 'DT')]\n",
      "[('are', 'VBP')]\n",
      "[('it', 'PRP')]\n",
      "[('and', 'CC')]\n",
      "[('these', 'DT')]\n",
      "[('are', 'VBP')]\n",
      "[('of', 'IN')]\n",
      "[('any', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('patterns', 'NNS')]\n",
      "[('are', 'VBP')]\n",
      "[('for', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('any', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('will', 'MD')]\n",
      "[('in', 'IN')]\n",
      "[('but', 'CC')]\n",
      "[('there', 'RB')]\n",
      "[('is', 'VBZ')]\n",
      "[('no', 'DT')]\n",
      "[('them', 'PRP')]\n",
      "[('from', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('or', 'CC')]\n",
      "[('to', 'TO')]\n",
      "[('be', 'VB')]\n",
      "[('against', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('it', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('such', 'JJ')]\n",
      "[('and', 'CC')]\n",
      "[('there', 'RB')]\n",
      "[('is', 'VBZ')]\n",
      "[('no', 'DT')]\n",
      "[('against', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('such', 'JJ')]\n",
      "[('with', 'IN')]\n",
      "[('such', 'JJ')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('or', 'CC')]\n",
      "[('a', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('an', 'DT')]\n",
      "[('on', 'IN')]\n",
      "[('his', 'PRP$')]\n",
      "[('or', 'CC')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('being', 'VBG')]\n",
      "[('so', 'RB')]\n",
      "[('that', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('patterns', 'NNS')]\n",
      "[('can', 'MD')]\n",
      "[('not', 'RB')]\n",
      "[('be', 'VB')]\n",
      "[('to', 'TO')]\n",
      "[('an', 'DT')]\n",
      "[('as', 'IN')]\n",
      "[('if', 'IN')]\n",
      "[('this', 'DT')]\n",
      "[('no', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('by', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('can', 'MD')]\n",
      "[('by', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('it', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('into', 'IN')]\n",
      "[('patterns', 'NNS')]\n",
      "[('from', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('a', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('that', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('a', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('or', 'CC')]\n",
      "[('in', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('out', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('this', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('by', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('of', 'IN')]\n",
      "[('this', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('by', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('by', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('that', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('such', 'JJ')]\n",
      "[('as', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('such', 'JJ')]\n",
      "[('as', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('some', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('but', 'CC')]\n",
      "[('they', 'PRP')]\n",
      "[('do', 'VB')]\n",
      "[('not', 'RB')]\n",
      "[('nor', 'CC')]\n",
      "[('or', 'CC')]\n",
      "[('have', 'VB')]\n",
      "[('to', 'TO')]\n",
      "[('more', 'RBR')]\n",
      "[('for', 'IN')]\n",
      "[('such', 'JJ')]\n",
      "[('as', 'IN')]\n",
      "[('as', 'IN')]\n",
      "[('as', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('to', 'TO')]\n",
      "[('a', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('that', 'IN')]\n",
      "[('can', 'MD')]\n",
      "[('or', 'CC')]\n",
      "[('on', 'IN')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('of', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('is', 'VBZ')]\n",
      "[('from', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('for', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('that', 'IN')]\n",
      "[('most', 'JJS')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('which', 'WDT')]\n",
      "[('is', 'VBZ')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('about', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('as', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('all', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('some', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('between', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('for', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('have', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('the', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('a', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('a', 'DT')]\n",
      "[('are', 'VBP')]\n",
      "[('to', 'TO')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('does', 'VBZ')]\n",
      "[('not', 'RB')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('this', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('we', 'PRP')]\n",
      "[('can', 'MD')]\n",
      "[('the', 'DT')]\n",
      "[('that', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('is', 'VBZ')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('is', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('an', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('are', 'VBP')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('are', 'VBP')]\n",
      "[('very', 'RB')]\n",
      "[('to', 'TO')]\n",
      "[('are', 'VBP')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('is', 'VBZ')]\n",
      "[('an', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('very', 'RB')]\n",
      "[('to', 'TO')]\n",
      "[('that', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('are', 'VBP')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('it', 'PRP')]\n",
      "[('into', 'IN')]\n",
      "[('then', 'RB')]\n",
      "[('other', 'JJ')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('patterns', 'NNS')]\n",
      "[('of', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('a', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('a', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('but', 'CC')]\n",
      "[('its', 'PRP$')]\n",
      "[('because', 'IN')]\n",
      "[('it', 'PRP')]\n",
      "[('has', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('this', 'DT')]\n",
      "[('by', 'IN')]\n",
      "[('more', 'RBR')]\n",
      "[('how', 'WRB')]\n",
      "[('and', 'CC')]\n",
      "[('when', 'WRB')]\n",
      "[('to', 'TO')]\n",
      "[('this', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('with', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('on', 'IN')]\n",
      "[('with', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('for', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('from', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('to', 'TO')]\n",
      "[('of', 'IN')]\n",
      "[('for', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('on', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('for', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('on', 'IN')]\n",
      "[('as', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('to', 'TO')]\n",
      "[('and', 'CC')]\n",
      "[('and', 'CC')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('in', 'IN')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('as', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('for', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('and', 'CC')]\n",
      "[('for', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('a', 'DT')]\n",
      "[('s', 'NN')]\n",
      "[('from', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('from', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('be', 'VB')]\n",
      "[('from', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('be', 'VB')]\n",
      "[('from', 'IN')]\n",
      "[('in', 'IN')]\n",
      "[('to', 'TO')]\n",
      "[('this', 'DT')]\n",
      "[('a', 'DT')]\n",
      "[('as', 'IN')]\n",
      "[('was', 'VBD')]\n",
      "[('on', 'IN')]\n",
      "[('at', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[('under', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('this', 'DT')]\n",
      "[('you', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('and', 'CC')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('a', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "for line in text:\n",
    "    line = line.split(\".\")\n",
    "    for sub_line in line:\n",
    "        wordsList = nltk.word_tokenize(sub_line)\n",
    "        for i in wordsList:\n",
    "            if i in stop_words:\n",
    "                wordsList2 = nltk.word_tokenize(i)\n",
    "                tagged = nltk.pos_tag(wordsList2) \n",
    "                print(tagged) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Ques3: Write a program to extract the contents (excluding any tags) from two websites (https://en.wikipedia.org/wiki/Web_mining & https://en.wikipedia.org/wiki/Data_mining) and save the content in two separate .doc file. Remove stopwords from the content and represent the documents using Boolean, Bag-of-words and Complete representation. Process a search a query and compare the contents of the both pages with the processed query, display the similarity result based on highest matching count (bag-of-words).\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = requests.get(\"https://en.wikipedia.org/wiki/Web_mining\")\n",
    "url2 = requests.get(\"https://en.wikipedia.org/wiki/Data_mining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(url1.text)\n",
    "soup2 = BeautifulSoup(url2.text)\n",
    "for script in soup1([\"script\", \"style\"]):\n",
    "    script.decompose()\n",
    "for script in soup2([\"script\", \"style\"]):\n",
    "    script.decompose()\n",
    "text1 = soup1.get_text()\n",
    "text2 = soup2.get_text()\n",
    "\n",
    "lines1 = (line.strip() for line in text1.splitlines())\n",
    "chunks1 = (phrase.strip() for line in lines1 for phrase in line.split(\"  \"))\n",
    "text1 = '\\n'.join(chunk for chunk in chunks1 if chunk)\n",
    "text1 = text1.lower()\n",
    "\n",
    "lines2 = (line.strip() for line in text2.splitlines())\n",
    "chunks2 = (phrase.strip() for line in lines2 for phrase in line.split(\"  \"))\n",
    "text2 = '\\n'.join(chunk for chunk in chunks2 if chunk)\n",
    "text2 = text2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = open(\"web_mining.doc\", \"w\", encoding='utf-8')\n",
    "doc1.write(text1)\n",
    "doc1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = open(\"data_mining.doc\", \"w\", encoding='utf-8')\n",
    "doc2.write(text2)\n",
    "doc2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens1 = word_tokenize(text1)\n",
    "word_tokens2 = word_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_text1 = [w for w in word_tokens1 if not w in stop_words]\n",
    "filt_text2 = [w for w in word_tokens2 if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = filt_text1 + filt_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(dict.fromkeys(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in_doc1 = [None]*len(all_words)\n",
    "word_in_doc2 = [None]*len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in all_words:\n",
    "    for j in filt_text1:\n",
    "        if i==j:\n",
    "            word_in_doc1[k] = 1\n",
    "            break\n",
    "    if word_in_doc1[k] != 1:\n",
    "        word_in_doc1[k] = 0\n",
    "    \n",
    "    for j in filt_text2:\n",
    "        if i==j:\n",
    "            word_in_doc2[k] = 1\n",
    "            break\n",
    "    if word_in_doc2[k] != 1:\n",
    "        word_in_doc2[k] = 0\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_rep = pd.DataFrame({\"Words\": all_words, \"Web Mining Doc\": word_in_doc1, \"Data Mining Doc\": word_in_doc2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Web Mining Doc</th>\n",
       "      <th>Data Mining Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>web</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mining</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words  Web Mining Doc  Data Mining Doc\n",
       "0        web               1                1\n",
       "1     mining               1                1\n",
       "2          -               1                1\n",
       "3  wikipedia               1                1\n",
       "4          ,               1                1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_rep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = open(\"web_mining.doc\", \"r\", encoding='utf-8')\n",
    "doc2 = open(\"data_mining.doc\", \"r\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups1 = {}\n",
    "groups2 = {}\n",
    "row = 0\n",
    "col = 0\n",
    "#for line in doc1:\n",
    "#    temp = line.split()\n",
    "#    row+=1\n",
    "for word1 in all_words:   \n",
    "    for line in doc1:\n",
    "        row+=1\n",
    "        temp = line.split()        \n",
    "        for word2 in temp:   \n",
    "            if(word1 == word2):\n",
    "                if word1 not in groups1.keys():\n",
    "                    groups1[word1] = list()\n",
    "                groups1[word1].append((row, col+1))\n",
    "            col+=len(word2)+1\n",
    "        col=0\n",
    "    if word1 not in groups1.keys():\n",
    "        groups1[word1] = list()\n",
    "    doc1.seek(0, 0)\n",
    "    \n",
    "    row=0\n",
    "    \n",
    "    for line in doc2:\n",
    "        row+=1\n",
    "        temp = line.split()        \n",
    "        for word2 in temp:   \n",
    "            if(word1 == word2):\n",
    "                if word1 not in groups2.keys():\n",
    "                    groups2[word1] = list()\n",
    "                groups2[word1].append((row, col+1))\n",
    "            col+=len(word2)+1\n",
    "        col=0\n",
    "    if word1 not in groups2.keys():\n",
    "        groups2[word1] = list()\n",
    "    doc2.seek(0, 0)\n",
    "    row=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_repr = pd.DataFrame({'Word': all_words, 'Position in Web Mining Doc': list(groups1.values()), 'Position in Data Mining Doc': list(groups2.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Position in Web Mining Doc</th>\n",
       "      <th>Position in Data Mining Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>web</td>\n",
       "      <td>[(1, 1), (2, 1), (7, 1), (8, 13), (8, 78), (8,...</td>\n",
       "      <td>[(203, 90), (213, 49), (280, 1), (302, 1), (35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mining</td>\n",
       "      <td>[(1, 5), (2, 5), (7, 5), (7, 39), (7, 157), (8...</td>\n",
       "      <td>[(1, 6), (2, 6), (6, 26), (99, 6), (99, 172), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>[(1, 12), (145, 52), (146, 40)]</td>\n",
       "      <td>[(1, 13), (207, 575), (218, 6), (327, 37), (33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>[(1, 14), (122, 23), (195, 7), (197, 9)]</td>\n",
       "      <td>[(1, 15), (647, 7), (649, 9)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word                         Position in Web Mining Doc  \\\n",
       "0        web  [(1, 1), (2, 1), (7, 1), (8, 13), (8, 78), (8,...   \n",
       "1     mining  [(1, 5), (2, 5), (7, 5), (7, 39), (7, 157), (8...   \n",
       "2          -                    [(1, 12), (145, 52), (146, 40)]   \n",
       "3  wikipedia           [(1, 14), (122, 23), (195, 7), (197, 9)]   \n",
       "4          ,                                                 []   \n",
       "\n",
       "                         Position in Data Mining Doc  \n",
       "0  [(203, 90), (213, 49), (280, 1), (302, 1), (35...  \n",
       "1  [(1, 6), (2, 6), (6, 26), (99, 6), (99, 172), ...  \n",
       "2  [(1, 13), (207, 575), (218, 6), (327, 37), (33...  \n",
       "3                      [(1, 15), (647, 7), (649, 9)]  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = [None]*complete_repr.shape[0]\n",
    "count2 = [None]*complete_repr.shape[0]\n",
    "for i in range(complete_repr.shape[0]):\n",
    "    count1[i] = len(complete_repr.loc[i, \"Position in Web Mining Doc\"])\n",
    "    count2[i] = len(complete_repr.loc[i, \"Position in Data Mining Doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame({'Word': all_words, 'Count in Web Mining Doc': count1, 'Count in Data Mining Doc': count2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Web Mining Doc</th>\n",
       "      <th>Count in Data Mining Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>web</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mining</td>\n",
       "      <td>70</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Count in Web Mining Doc  Count in Data Mining Doc\n",
       "0        web                      102                         6\n",
       "1     mining                       70                       115\n",
       "2          -                        3                         7\n",
       "3  wikipedia                        4                         3\n",
       "4          ,                        0                         0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence to search: web mining wikipedia\n"
     ]
    }
   ],
   "source": [
    "search_word = str(input(\"Enter a sentence to search: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['web', 'mining', 'wikipedia']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_word = search_word.split()\n",
    "search_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of search query in Web Mining Doc is 176\n",
      "Frequency of search query in Data Mining Doc is 124\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in search_word:\n",
    "    indx = bag_of_words.loc[bag_of_words['Word'] == i]\n",
    "    count1+=indx[\"Count in Web Mining Doc\"][indx.index.tolist()[0]]\n",
    "    count2+=indx[\"Count in Data Mining Doc\"][indx.index.tolist()[0]]\n",
    "print(\"Frequency of search query in Web Mining Doc is\", count1)\n",
    "print(\"Frequency of search query in Data Mining Doc is\", count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Quest4: Write a program to show the implementation of sentence paraphrasing through synonyms (retaining semantic meaning) for the following four sentences. Display at least three other paraphrased sentences for each sentence mentioned below.\n",
    "<br>a. The quick brown fox jumps over the lazy dog\n",
    "<br>b. Obama and Putin met the previous week\n",
    "<br>c. At least 12 people were killed in the battle last week\n",
    "<br>d. I will go home and come back tomorrow.\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import random\n",
    "\n",
    "def tag(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    words = pos_tag(words)\n",
    "    return words\n",
    "\n",
    "def paraphraseable(tag):\n",
    "    return tag.startswith('NN') or tag == 'VB' or tag.startswith('JJ')\n",
    "\n",
    "def pos(tag):\n",
    "    if tag.startswith('NN'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "\n",
    "def synonyms(word, tag):\n",
    "    lemma_lists = [ss.lemmas() for ss in wn.synsets(word, pos(tag))]\n",
    "    lemmas = [lemma.name() for lemma in sum(lemma_lists, [])]\n",
    "    return set(lemmas)\n",
    "\n",
    "\n",
    "def question(sentence):\n",
    "    directory = {}\n",
    "    for (word, t) in tag(sentence):\n",
    "        if paraphraseable(t):\n",
    "            syns = synonyms(word, t)\n",
    "            if syns:\n",
    "                if len(syns) > 1:\n",
    "                    directory[word] = list(syns)\n",
    "                    continue\n",
    "        directory[word] = []\n",
    "    new_sentence = [\"\", \"\", \"\"]\n",
    "    for i in range(3):\n",
    "        for word in sentence.split():\n",
    "            if len(directory[word]) == 0:\n",
    "                new_sentence[i] = new_sentence[i]+word+\" \"\n",
    "            else:\n",
    "                new_sentence[i] = new_sentence[i]+random.choice(directory[word])+\" \"\n",
    "    print(\"Paraphrase for\", \"\\\"\",sentence, \"\\\"\", \"----->\")\n",
    "    for i in new_sentence:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrase for \" The quick brown fox jumps over the lazy dog \" ----->\n",
      "The prompt Brown_University slyboots jumps over the lazy dog \n",
      "The promptly John_Brown George_Fox jumps over the work-shy dog-iron \n",
      "The immediate brownness dodger jumps over the slothful cad \n",
      "Paraphrase for \" Obama and Putin met the previous week \" ----->\n",
      "Obama and Putin met the late week \n",
      "Obama and Vladimir_Vladimirovich_Putin met the old workweek \n",
      "Obama and Vladimir_Putin met the late hebdomad \n",
      "Paraphrase for \" At least 12 people were killed in the battle last week \" ----->\n",
      "At least 12 people were killed in the conflict endure workweek \n",
      "At least 12 mass were killed in the fight final week \n",
      "At least 12 hoi_polloi were killed in the battle in_conclusion week \n",
      "Paraphrase for \"  I will go home and come back tomorrow \" ----->\n",
      "I will endure home_plate and add_up back tomorrow \n",
      "I will proceed dwelling and amount back tomorrow \n",
      "I will hold_up base and come_up back tomorrow \n"
     ]
    }
   ],
   "source": [
    "question(\"The quick brown fox jumps over the lazy dog\")\n",
    "question(\"Obama and Putin met the previous week\")\n",
    "question(\"At least 12 people were killed in the battle last week\")\n",
    "question(\" I will go home and come back tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
